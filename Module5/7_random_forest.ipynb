{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуальная демонстрация алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0fff3; padding: 15px; color: black; width: 80%;\">  <b>Случайный лес (Random Forest)</b> — это алгоритм машинного обучения, который используется для задач классификации и регрессии. Он является композицией решающих деревьев, где каждое дерево обучается независимо от других на разных случайных подвыборках данных и с разными случайными подмножествами признаков в каждой вершине.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При построении случайного леса сначала случайным образом выбирается подмножество обучающих данных (bootstrap-выборка) и подмножество признаков в каждой вершине. Затем на этом подмножестве строится решающее дерево с использованием выбранных признаков.\n",
    "\n",
    "Этот процесс повторяется много раз, что приводит к созданию ансамбля решающих деревьев. При предсказании каждое дерево выдаёт свой ответ, а итоговый ответ случайного леса определяется путём голосования или усреднения ответов всех деревьев.\n",
    "\n",
    "Визуальная демонстрация алгоритма представлена на рисунке ниже:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_5_14.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы строим композицию из пяти деревьев. Далее <b>для каждого нового узла с предикатами выбирается своё подмножество признаков</b>. Как мы упоминали, при классическом бэггинге подмножество признаков выбирается для каждого дерева, поэтому в это подмножество могут не попасть какие-нибудь важные признаки. Поэтому в random forest подмножества выбираются для каждой вершины с предикатами.\n",
    "\n",
    "Для нового объекта строится предсказание по каждому дереву, затем происходит голосование по большинству для классификации или усреднение — для регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм случайного леса — один из наиболее популярных алгоритмов машинного обучения, используемых для задач классификации, регрессии и кластеризации. Он основан на идее комбинации нескольких решающих деревьев для улучшения точности прогнозирования.\n",
    "\n",
    "Вот шаги, которые выполняет алгоритм random forest:\n",
    "\n",
    "1. Из обучающей выборки случайным образом выбирается подмножество объектов.\n",
    "2. На этом подмножестве строится решающее дерево.\n",
    "3. В каждом нелистовом узле дерева выбирается подмножество признаков и оптимальный предикат в соответствии с критерием информативности. Рекомендовано брать $ 1/3$ всех признаков для задач регрессии и $ \\sqrt{d}$— для задач классификации, где $d$— размерность признакового пространства.\n",
    "4. Для каждого дерева в случайном лесу применяется тестирование на обучающей выборке и определяется его точность.\n",
    "5. Предсказание для нового объекта делается на основе агрегирования предсказаний всех деревьев в случайном лесу, например путём голосования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; padding: 15px; color: black; width: 80%;\">Таким образом, random forest создаёт ансамбль решающих деревьев, который демонстрирует лучшую точность, чем каждое отдельное дерево. Он также способен автоматически обрабатывать пропущенные значения, шум и выбросы в данных. Этот алгоритм легко распараллеливается, что делает его эффективным на больших датасетах.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных для алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка данных для алгоритма может включать в себя следующие шаги:\n",
    "\n",
    "- <b>Работа с пропущенными значениями</b>. Случайный лес не может работать с пропущенными значениями. Можно решить эту проблему, заполнив пропуски средними или медианными значениями для числовых признаков или модой — для категориальных.\n",
    "- <b>Работа с выбросами</b>. Случайный лес не чувствителен к выбросам, но они могут негативно повлиять на качество модели, особенно если их много. Можно применить различные методы обработки выбросов.\n",
    "- <b>Преобразование категориальных переменных в числовые</b>. Случайный лес не может напрямую работать с категориальными переменными, поэтому их необходимо преобразовать в числовые.\n",
    "- <b>Разделение данных на обучающую и тестовую выборки</b>.\n",
    "- <b>Отбор признаков</b>. Если в наборе данных много признаков, можно использовать методы их отбора, такие как метод главных компонент или методы выбора признаков на основе значимости, чтобы уменьшить количество признаков и улучшить производительность модели.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Процесс обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Процесс обучения случайного леса включает в себя следующие шаги:\n",
    "\n",
    "1. Для каждого из деревьев в ансамбле производится случайный выбор подмножества данных из обучающей выборки. Этот шаг называется подвыборкой с заменой (bootstrapping).\n",
    "2. Случайный выбор подмножества признаков для каждого нелистового узла в дереве. Обычно для каждого узла выбирается $\\sqrt{d}$ признаков, где $d$ — общее количество признаков.\n",
    "3. Построение деревьев. Для каждой выборки данных и подмножества признаков строится дерево решений. Деревья строятся до определённой глубины или до тех пор, пока каждый лист не будет содержать минимальное количество примеров.\n",
    "4. Прогнозирование. Для каждого нового примера производится прогноз с помощью каждого дерева. Класс, выбранный большинством деревьев, становится итоговым прогнозом.\n",
    "5. Тюнинг гиперпараметров. Для улучшения качества модели можно провести тюнинг гиперпараметров, таких как количество деревьев, глубина деревьев, размер подвыборки и т. д.\n",
    "6. Повторение. Шаги 1–5 повторяются несколько раз для получения стабильного прогноза."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; padding: 15px; color: black; width: 80%;\">В результате обучения случайного леса получается ансамбль деревьев, каждое из которых принимает решение на основе случайной подвыборки данных и признаков. Это помогает уменьшить переобучение и увеличить стабильность модели. Кроме того, случайный лес может обрабатывать данные с большим количеством признаков и работать с несбалансированными данными.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки качества алгоритма логистической регрессии часто используют следующие метрики:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Классификация:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Accuracy:</b> $\\frac{TP+TN}{TP+TN+FP+FN}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Precision:</b>$\\frac{TP}{TP+FP}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Recall:</b>$\\frac{TP}{TP+FN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>F1: </b> $2* \\frac{precision*recall}{precision+recall}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Регрессия:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MSE\n",
    "- MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Интерпретация признаков с помощью алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайный лес может рассчитывать важность признаков (например, с помощью критерия Джини или прироста информации) на основе их вклада в уменьшение критерия ошибки.\n",
    "\n",
    "Важность признака можно использовать для оценки вклада признака в предсказание целевой переменной. Признаки с более высокой важностью считаются более значимыми для модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модификации алгоритма\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует несколько модификаций алгоритма случайного леса, которые можно применять в зависимости от задачи и данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот некоторые из них:\n",
    "\n",
    "- <b>Random Decision Forest (RDF)</b> — это расширение стандартного случайного леса, которое использует случайное количество деревьев для каждого класса. Это может улучшить предсказания в ситуациях, когда классы имеют различные размеры.\n",
    "- <b>Balanced Random Forest (BRF)</b> — это модификация случайного леса, в которой используется взвешенное голосование деревьев, чтобы уравновесить несбалансированные данные. Каждое дерево в BRF обучается на случайном подмножестве данных, сбалансированном по классам.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Область применения алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые из основных областей применения алгоритма случайного леса:\n",
    "\n",
    "- Финансы. Анализ кредитных рисков, определение мошенничества, прогнозирование финансовых показателей.\n",
    "- Медицина. Диагностика заболеваний, прогнозирование риска заболеваний, анализ медицинских данных.\n",
    "- Реклама. Прогнозирование эффективности рекламы, анализ поведения потребителей.\n",
    "- Интернет-магазины. Рекомендательные системы, прогнозирование продаж, сегментация аудитории.\n",
    "- Обработка естественного языка. Классификация текстов, анализ тональности.\n",
    "- Изображения и видео. Распознавание объектов, классификация изображений, анализ видео.\n",
    "- Промышленность. Мониторинг и управление качеством продукции, прогнозирование отказов оборудования.\n",
    "- Транспорт и логистика. Прогнозирование спроса на перевозки, оптимизация маршрутов, анализ логистических данных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом, алгоритм случайного леса может быть полезным в любой области, где требуется классификация или регрессия на основе большого количества признаков и где есть достаточно данных для обучения модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Плюсы и минусы алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "😃\n",
    "- Хорошая точность предсказаний. Случайный лес обладает хорошей точностью при классификации и регрессии, особенно при использовании большого количества деревьев в лесу.\n",
    "- Устойчивость к переобучению. Случайность выборки и выбора признаков делает случайный лес устойчивым к выбросам и шуму в данных.\n",
    "- Высокая скорость обучения. Обучение случайного леса можно распараллелить, что позволяет быстро обрабатывать большие объёмы данных.\n",
    "- Возможность оценки важности признаков. Случайный лес может определить наиболее важные признаки для классификации или регрессии.\n",
    "- Универсальность. Алгоритм случайного леса можно применять для широкого круга задач машинного обучения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \t😩\n",
    "- Неинтерпретируемость. Каждое дерево в случайном лесу можно интерпретировать, но сам алгоритм не даёт понять, как именно происходит принятие решения.\n",
    "- Высокая вычислительная сложность. Поскольку в случайном лесу много деревьев, обработка данных может занять длительное время.\n",
    "- Зависимость от выбора гиперпараметров. Для достижения наилучшей производительности необходимо подбирать гиперпараметры, такие как количество деревьев и максимальная глубина дерева.\n",
    "- Неэффективность для работы со множеством категориальных признаков. Алгоритм случайного леса не всегда хорошо работает с большим количеством категориальных признаков, поскольку в таком случае деревья могут становиться слишком глубокими.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; padding: 15px; color: black; width: 80%;\">В целом, алгоритм случайного леса — мощный инструмент машинного обучения, обладающий высокой точностью предсказания и способностью устранять переобучение. При этом он требует тщательной настройки гиперпараметров и может быть неэффективным при работе с большим количеством категориальных признаков.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке Scikit-learn для алгоритма случайного леса реализован класс RandomForestClassifier. Основные параметры класса:\n",
    "\n",
    "- n_estimators — количество деревьев в лесу. По умолчанию n_estimators=100.\n",
    "- criterion — функция для измерения качества разделения. Поддерживаются два значения: gini — для критерия Джини и entropy — для критерия энтропии. По умолчанию criterion=gini.\n",
    "- max_depth — максимальная глубина каждого дерева в лесу. По умолчанию max_depth=None, что означает, что деревья разрастаются до тех пор, пока все листья не будут чистыми (т. е. будут содержать только элементы одного класса) или пока не будет достигнуто минимальное количество элементов для разделения.\n",
    "- min_samples_split — минимальное количество элементов, необходимое для того, чтобы узел можно было разделить на два подузла. По умолчанию min_samples_split=2.\n",
    "- min_samples_leaf — минимальное количество элементов, которые должны быть в листьях дерева. По умолчанию min_samples_leaf=1.\n",
    "- min_weight_fraction_leaf — минимальная доля суммы весов (всех элементов), которая должна быть в листьях дерева. По умолчанию min_weight_fraction_leaf=0.0.\n",
    "- max_features — количество признаков, которые должны быть рассмотрены при каждом разделении. Поддерживаются следующие значения:\n",
    "  - auto — выбор sqrt(n_features) признаков;\n",
    "  - sqrt — то же, что и auto;\n",
    "  - log2 — выбор log2(n_features) признаков;\n",
    "  - None — выбор всех признаков;\n",
    "  - целое число — выбор конкретного количества признаков;\n",
    "  - доля — выбор доли от общего количества признаков.\n",
    "\n",
    "    По умолчанию max_features=auto.\n",
    "- max_leaf_nodes — максимальное количество листьев в дереве. По умолчанию max_leaf_nodes=None, что означает, что нет ограничения на количество листьев.\n",
    "\n",
    "Класс RandomForestRegressor для решения задач регрессии имеет практически те же параметры, за исключением:\n",
    "\n",
    " -   criterion — функция для измерения качества разделения. Поддерживаются значения: squared_error, absolute_error, friedman_mse, poisson. По умолчанию criterion=squared_error.\n",
    "\n",
    "У классов RandomForestClassifier и RandomForestRegressor есть методы fit(X, y) для обучения модели на данных X и y, а также метод predict(X) для предсказания целевых значений для новых данных X.\n",
    "\n",
    "Кроме того, классы RandomForestClassifier и RandomForestRegressor имеют методы score(X, y) и get_params() для получения оценки точности модели и параметров модели соответственно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; padding: 15px; color: black; width: 80%;\">Алгоритм случайного леса основан на идее комбинирования нескольких деревьев решений, обученных на разных подмножествах признаков в каждой нелистовой вершине и подмножествах объектов. В результате получается ансамбль деревьев, который позволяет уменьшить влияние переобучения и повысить точность классификации или регрессии.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0ffd1;color: black;border: 3px solid black; padding: 15px; margin-right: 500px; width: 80%;\">Одно из ключевых преимуществ случайного леса — его способность работать с большим количеством признаков и наблюдений, что делает его подходящим для обработки сложных и многоуровневых данных. Кроме того, случайный лес можно использовать для интерпретации важности признаков, что может быть полезно для понимания вклада каждого признака в процесс принятия решения.</div>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
