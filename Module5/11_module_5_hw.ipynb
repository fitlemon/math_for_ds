{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем проверять задания:\n",
    "- **Перезапустите ядро** (**restart the kernel**) (В меню, выбрать Ядро (Kernel) $\\rightarrow$ Перезапустить (Restart)\n",
    "- Затем **Выполнить все ячейки**  **run all cells** (В меню, выбрать Ячейка (Cell) $\\rightarrow$ Запустить все (Run All).\n",
    "\n",
    "Убедитесь, что заполнены все ячейки с комментарием \"НАЧАЛО ВАШЕГО РЕШЕНИЯ\".\n",
    "\n",
    "После ячеек с заданием следуют ячейки с проверкой с помощью assert.\n",
    "\n",
    "Если в коде есть ошибки, assert выведет уведомление об ошибке.\n",
    "\n",
    "Если в коде нет ошибок, assert отработает без вывода дополнительной информации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb539edbcb31a15b083fea0c484d7061",
     "grade": false,
     "grade_id": "cell-9bf354ef0a7b3bab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Цель занятия\n",
    "На этом занятии мы на практике закрепим работу с решающими деревьями, композициями деревьев на основе бэггинга и случайного леса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b2003ebfd0f5a46323f891b28b8c237",
     "grade": false,
     "grade_id": "cell-ad0908409300e6db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Решающее дерево** - это алгоритм машинного обучения, который используется для решения задач классификации и регрессии. Оно представляет собой древовидную структуру, где каждый узел представляет тест на одном из признаков, а каждая ветвь - возможный результат этого теста. Листья дерева представляют собой конечный результат - прогноз для новых данных.\n",
    "\n",
    "В процессе построения решающего дерева, алгоритм выбирает тест, который лучше всего разделяет данные на различные классы или предсказывает значение целевой переменной. Затем данные разбиваются на две или более частей в соответствии с результатами теста. Этот процесс повторяется для каждой полученной части, пока не будет достигнут критерий останова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de60f66251d737c37f6d25cd83c22326",
     "grade": false,
     "grade_id": "cell-c37a4ea3f59325d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# импорт необходимых библиотек\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Задание 1. Реализация критерия Джини.\n",
    "\n",
    "Функция gini_index принимает вектор y с дискретными значениями и вычисляет значение критерия Джини для данного вектора. В функции gini_index сначала подсчитывается количество уникальных значений в векторе y, затем вычисляется вероятность каждого уникального значения и, наконец, вычисляется значение критерия Джини. Отличие заключается в том, что значение критерия Джини вычисляется по формуле 1 - сумма квадратов вероятностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89a7174dc0787bd1c51c38ecc3e28474",
     "grade": false,
     "grade_id": "cell-a3e6f52bfbf18e37",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Завершите реализацию функции gini_index \n",
    "\n",
    "def gini_index(y):\n",
    "\n",
    "    # Вычисляет критерий Джини для вектора y со значениями дискретных переменных.\n",
    "\n",
    "    # Аргументы:\n",
    "    # - y: вектор numpy с дискретными значениями.\n",
    "\n",
    "    # Возвращает:\n",
    "    # - gini: значение критерия Джини типа float.\n",
    "\n",
    "    # Подсчитываем количество каждого уникального значения в y.\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    # Вычисляем вероятность каждого уникального значения.\n",
    "    probs = counts / len(y)\n",
    "    \n",
    "    if not len(probs):\n",
    "        return 0\n",
    "    \n",
    "    \"\"\"\n",
    "    Вычислите значение критерия Джини и запишите его в переменную criterion\n",
    "    Формула критерия Джини: 1 - сумма квадратов вероятностей  \n",
    "    Пример для энтропии: criterion = -np.sum(probs * np.log2(probs)) !!! заменить на формулу для Джини\n",
    "    \"\"\"\n",
    "    # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "    raise NotImplementedError()\n",
    "    # КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "    \n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44f5914eb99c4c600d56120ddd3763bf",
     "grade": true,
     "grade_id": "cell-0d95db3083a6ee39",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Пустой вектор: \n",
    "assert gini_index(np.array([])) == 0\n",
    "# Вектор с одним элементом:\n",
    "assert gini_index(np.array([1])) == 0\n",
    "# Вектор с двумя одинаковыми элементами: \n",
    "assert gini_index(np.array([2,2])) == 0\n",
    "# Вектор с двумя разными элементами: \n",
    "assert gini_index(np.array([1,2])) == 0.5\n",
    "# Вектор с тремя одинаковыми элементами: \n",
    "assert gini_index(np.array([0,0,0])) == 0\n",
    "# Вектор с тремя элементами, два из которых одинаковые: \n",
    "assert gini_index(np.array([0,0,1])) == 0.4444444444444444\n",
    "# Вектор с тремя элементами, все элементы разные: \n",
    "assert gini_index(np.array([1,2,3])) == 0.6666666666666667\n",
    "# Вектор с четырьмя одинаковыми элементами: \n",
    "assert gini_index(np.array([7,7,7,7])) == 0\n",
    "# Вектор с четырьмя элементами, два из которых одинаковые: \n",
    "assert gini_index(np.array([5,5,2,1])) == 0.625\n",
    "# Вектор с пятью элементами, все элементы разные:\n",
    "assert np.isclose(gini_index(np.array([5,4,3,2,1])), 0.7999999999999998, atol=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1.  Задание 2. Реализация прироста информации на основе критерия Джини.\n",
    "\n",
    "Для реализации прироста информации на основе критерия Джини для вектора признаков нужно вычислить критерий Джини для каждого разбиения и выбрать разбиение с наименьшим критерием Джини. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "982749a66c32ac2c6b012e30c85a0519",
     "grade": false,
     "grade_id": "cell-42d71d240347b2d2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def find_best_split_gini(X, y):\n",
    "\n",
    "    # Находит лучшее разбиение для вектора признаков X и вектора целевой переменной y, используя критерий Джини.\n",
    "\n",
    "    # Аргументы:\n",
    "    # - X: вектор numpy с вещественными значениями признаков.\n",
    "    # - y: вектор numpy с дискретными значениями целевой переменной.\n",
    "\n",
    "    # Возвращает:\n",
    "    # - best_feature: индекс признака, по которому было найдено лучшее разбиение.\n",
    "    # - best_threshold: значение порога, по которому было найдено лучшее разбиение.\n",
    "    # - best_gain: значение критерия энтропии для лучшего разбиения.\n",
    "\n",
    "    best_feature, best_threshold, best_gain = None, None, 0\n",
    "    # Итерируемся по всем признакам.\n",
    "    for feature in range(X.shape[1]):\n",
    "        # Находим уникальные значения признака.\n",
    "        thresholds = np.unique(X[:, feature])\n",
    "        # Итерируемся по всем возможным пороговым значениям признака.\n",
    "        for threshold in thresholds:\n",
    "            # Определяем индексы объектов, которые относятся к левому поддереву и правому поддереву.\n",
    "            left_indices = X[:, feature] <= threshold\n",
    "            right_indices = X[:, feature] > threshold\n",
    "            # Пропускаем текущую итерацию, если не найдены объекты, которые относятся к левому или правому поддереву.\n",
    "            if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "                continue\n",
    "            # Определяем вектор целевой переменной для объектов, которые относятся к левому и правому поддереву.\n",
    "            left_y, right_y = y[left_indices], y[right_indices]\n",
    "            \"\"\"\n",
    "            Вычисляем значение прироста информации для текущего разбиения.\n",
    "            Необходимо сохранить результат вычисления в переменную gain\n",
    "            Пример для энтропии: \n",
    "            gain = entropy(y) - (len(left_y) / len(y)) * entropy(left_y) - (len(right_y) / len(y)) * entropy(right_y) \n",
    "            !!! заменить на вычисление критерия Джини\n",
    "            \"\"\"\n",
    "            # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "            raise NotImplementedError()\n",
    "            # КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "            # Обновляем значения лучшего разбиения, если найдено разбиение с большим значением\n",
    "            if gain > best_gain:\n",
    "                best_feature, best_threshold, best_gain = feature, threshold, gain\n",
    "    return best_feature, best_threshold, best_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2a92ecc40cc66f97fdea2da2d7e59d2",
     "grade": true,
     "grade_id": "cell-d93de88faeb7870d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Проверим, что функция `find_best_split_gini` работает правильно на примере:\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])\n",
    "y = np.array([0, 1, 1, 0, 1])\n",
    "\n",
    "best_feature, best_threshold, best_gain = find_best_split_gini(X, y)\n",
    "\n",
    "\n",
    "assert best_feature == 0\n",
    "assert best_threshold == 1\n",
    "assert round(best_gain, 2) == 0.18\n",
    "\n",
    "\n",
    "# Проверим, что функция `find_best_split_gini` работает правильно на примере, когда все элементы одного класса:\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])\n",
    "y = np.array([0, 0, 0, 0, 0])\n",
    "\n",
    "best_feature, best_threshold, best_gain = find_best_split_gini(X, y)\n",
    "\n",
    "assert best_feature is None\n",
    "assert best_threshold is None\n",
    "assert best_gain == 0\n",
    "\n",
    "\n",
    "# Проверим, что функция `find_best_split_gini` работает правильно на примере, когда все признаки одинаковы:\n",
    "\n",
    "X = np.array([[1, 1], [1, 1], [1, 1], [1, 1], [1, 1]])\n",
    "y = np.array([0, 1, 1, 0, 1])\n",
    "\n",
    "best_feature, best_threshold, best_gain = find_best_split_gini(X, y)\n",
    "\n",
    "assert best_feature is None\n",
    "assert best_threshold is None\n",
    "assert best_gain == 0\n",
    "\n",
    "\n",
    "# Проверим, что функция `find_best_split_gini` работает правильно на примере, когда все элементы разных классов:\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])\n",
    "y = np.array([0, 1, 0, 1, 0])\n",
    "\n",
    "best_feature, best_threshold, best_gain = find_best_split_gini(X, y)\n",
    "\n",
    "assert best_feature == 0\n",
    "assert best_threshold == 1\n",
    "assert round(best_gain, 2) == 0.08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4ca75c9a2e41994e7337ba80acf0ed2",
     "grade": false,
     "grade_id": "cell-332919cbfa1f2c05",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Часть 2. Задание 3. Бэггинг для классификации\n",
    "\n",
    "В этом примере мы воспользуемся набором данных Iris.\n",
    "\n",
    "Нужно будет определить базовый оценщик как решающее дерево классификации, определить BaggingClassifier с количеством оценщиков n_estimators равным 10. Затем мы обучим модель на обучающем наборе данных и оценим ее производительность на тестовом наборе данных с помощью метрики точности (accuracy_score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9f738a096d2d17ee738cac7c4466924",
     "grade": false,
     "grade_id": "cell-8fc463e3a569e5e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Загрузка библиотек\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Загрузка датасета\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Разделение набора данных на обучающий и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3814d3ff67a3ade8b3aea3fbb500b933",
     "grade": false,
     "grade_id": "cell-c16141ee4486a672",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Инициализируйте бэггинг-классификатор на основе класса BaggingClassifier, \n",
    "в параметр estimator передайте значение DecisionTreeClassifier(), \n",
    "в параметр n_estimators - значение 30, \n",
    "в параметр random_state - значение 0.\n",
    "Экземпляр сохраните в переменную bagging\n",
    "\n",
    "Пример с другой моделью:\n",
    "bagging = BaggingClassifier(estimator=SVC(), n_estimators=10, random_state=1)\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c34727cdce3e996b33b5b3bd65f2328a",
     "grade": true,
     "grade_id": "cell-a4b7b7488c61e7e9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(bagging) == BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26f9bed7b03b1e10935fed8dac791115",
     "grade": false,
     "grade_id": "cell-1c98d09d5490639c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Обучение бэггинг-классификатора на обучающем наборе\n",
    "bagging.fit(X_train, y_train)\n",
    "\n",
    "# Оценка производительности бэггинг-классификатора на тестовом наборе\n",
    "y_pred = bagging.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57f7d02f1664e064ffa94e906acc207f",
     "grade": false,
     "grade_id": "cell-33acde160292af9b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Посчитайте f1_macro метрику для трех классов и сохраните в переменную f1_macro\n",
    "Пример для f1_micro:\n",
    "f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "\"\"\"\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ\n",
    "\n",
    "print(\"f1_macro:\", f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9c18256d05493197eafe4e9cbd56cb3",
     "grade": true,
     "grade_id": "cell-b68bea2a867a40ce",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert f1_macro > 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "91b88bf44d770c08dd5b2d59408cbee6",
     "grade": false,
     "grade_id": "cell-7d570636228d9211",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Часть 3. Задание 4. Случайный лес для регрессии\n",
    "\n",
    "Случайный лес (Random Forest) - это алгоритм машинного обучения, который является комбинацией множества решающих деревьев. Он применяется как для задач классификации, так и для задач регрессии.\n",
    "\n",
    "Суть метода заключается в том, что мы строим несколько деревьев решений на случайных подмножествах данных и случайных подмножествах признаков на каждом нелистовом узле, а затем усредняем их ответы для уменьшения эффекта переобучения. Для каждого дерева в случайном лесу используется только подмножество данных, которое выбирается случайным образом с возвращением (bootstrap).\n",
    "\n",
    "Кроме того, для каждого разбиения дерева в случайном лесу выбирается только подмножество признаков, которые можно использовать для разделения узлов. Это позволяет получить более разнообразные деревья и уменьшить вероятность переобучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "541f02d21d69d2a50aab2bfc45975250",
     "grade": false,
     "grade_id": "cell-4b968d3440b77d2c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# загрузка библиотек\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87555a771029f1fbe0003cec2d3a8b17",
     "grade": false,
     "grade_id": "cell-c2ae8e3c342c443c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# загрузка датасета\n",
    "df = pd.read_csv(\"Boston.csv\", header=0, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8868d56b90dcccb8b3626ef309217908",
     "grade": false,
     "grade_id": "cell-af8e59f874d6670f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Разделим данные на тренировочную и тестовую выборки:\n",
    "X = df.drop('medv', axis=1)\n",
    "y = df['medv']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ab20963b12075c893e1b465556cfb89",
     "grade": false,
     "grade_id": "cell-0807738669e9b21b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Инициализируйте экземпляр класса RandomForestRegressor, \n",
    "в параметр n_estimators передайте значение 100, \n",
    "в параметр max_depth - значение 5, \n",
    "в параметр random_state - значение 0.\n",
    "Экземпляр сохраните в переменную rfr\n",
    "\n",
    "Пример с другой моделью:\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "\"\"\"\n",
    "\n",
    "# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n",
    "raise NotImplementedError()\n",
    "# КОНЕЦ ВАШЕГО РЕШЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee6f14c7e9e740355ea8cd4628a99a26",
     "grade": true,
     "grade_id": "cell-31e4b54fb1755366",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(rfr) == RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "acea0e63e54bcdb3be5d31fccaf60b08",
     "grade": false,
     "grade_id": "cell-21a8310731ed17f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "rfr.fit(X_train, y_train)\n",
    "# Оценим качество модели на тестовой выборке с использованием метрики MAE:\n",
    "y_pred = rfr.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"MAE:\", mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
