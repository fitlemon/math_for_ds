### <img src='../static/img/mipt-icon.png' width="70" height="30"> Курс "Математика для Машинного обучения" (Магистратура "Науки о данных" МФТИ - 2023/2025) 
---
 :house: [Вернуться на главный экран](..)
# Конспект по Модулю #5 **    Деревья решений. Композиции деревьев. Случайный лес**  :blue_book:


## Оглавление конспекта
1. [Деревья решений](1_decision_tree.ipynb) 
2. [Деревья решений. Реализация](2_decision_tree_practice.ipynb) 
3. [Деревья решений. Практика. Классификация](3_practice_classification_decision_tree.ipynb)  
4. [Деревья решений. Практика. Регрессия](4_practice_regression_decision_tree.ipynb)
5. [Композиция деревьев](5_tree_composition.ipynb)
6. [Композиция деревьев. Практика](6_tree_composition_practice.ipynb)
7. [Случайный лес](7_random_forest.ipynb)
8. [Случайный лес. Реализиция](8_random_forest_realisation.ipynb)
9. [Случайный лес. Практика. Классификация](9_practice_classification_random_forest.ipynb)
10. [Случайный лес. Практика. Регрессия](10_practice_regression_random_forest.ipynb)
11. [Домашнее задание по модулю](11_module_5_hw.ipynb)
12. [Семинар по модулю №5](lecture_05_code_online_01.ipynb)

---

### Дополнительная информация по модулю: :books:
1. [What is the difference between bagging and random forest if only one explanatory variable is used?](https://stats.stackexchange.com/questions/264129/what-is-the-difference-between-bagging-and-random-forest-if-only-one-explanatory)
2. [Difference between min_samples_split and min_samples_leaf in sklearn DecisionTreeClassifier](https://stackoverflow.com/questions/46480457/difference-between-min-samples-split-and-min-samples-leaf-in-sklearn-decisiontre)
3. [Decision Trees](https://julienbeaulieu.gitbook.io/wiki/sciences/machine-learning/decision-trees)
4. [9.1. Bias-variance decomposition ](https://education.yandex.ru/handbook/ml/article/bias-variance-decomposition)
5. [Б.ггинг, случайны елеса и разложение ошибки на смещение и разброс (Соколов ФКН ВШЭ)](https://github.com/esokolov/ml-course-hse/blob/master/2020-fall/lecture-notes/lecture08-ensembles.pdf)
6. [Случайный лес, бустинг и bias-variance tradeoff](https://github.com/Murcha1990/ML_econom_2022-2023/blob/main/%D0%A1%D0%B5%D0%BC%D0%B8%D0%BD%D0%B0%D1%80%D1%8B/%D0%A1%D0%B5%D0%BC%D0%B8%D0%BD%D0%B0%D1%80%209/Seminar9_2022.ipynb)
