{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid white; padding: 5px; margin-right: auto;  width: 80%;\"><b>Цель занятия</b> — познакомиться с композициями деревьев решений и понятиями смещения и разброса, которые связаны с оценкой обобщающей способности композиции моделей.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решающее дерево — хороший инструмент для прогнозирования на данных. Однако этот инструмент обладает одним ярко выраженным недостатком — нестабильностью. При применении моделей мы обычно ожидаем, что на приблизительно одинаковых данных мы получим схожие модели. С решающими деревьями это не так: даже при небольшом изменении выборки решающее дерево сильно изменяет разделяющую поверхность, что является признаком переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_5_8.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На рисунке выше видно, что одиночное решающее дерево достаточно сильно изменяется при небольшом изменении данных. Однако есть способ борьбы с такой формой переобучения — это агрегирование прогнозов по нескольким решающим деревьям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подходы к построению композиций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В машинном обучении агрегирование нескольких моделей для получения более точного и устойчивого прогноза называется <b>композицией моделей</b>, или <b>ансамблированием.</b>\n",
    "\n",
    "В целом, композиция моделей на основе деревьев решений может значительно повысить качество предсказаний в задачах классификации и регрессии.\n",
    "\n",
    "Наиболее простой способ определения класса для композиции деревьев — <b>голосование по большинству (majority vote):</b> это когда метка класса присваивается по относительному большинству отдельных моделей, предсказавших её."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_5_9.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При одинаковом количестве голосов существуют разные стратегии: случайный выбор, приоритет определённых классов и пр. Для регрессии наиболее очевидный способ агрегирования — это усреднение предсказаний моделей из композиции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; padding: 15px; color: black; width: 80%;\">Бэггинг (bootstrap aggregating) и бустинг (boosting) — два популярных подхода к построению композиций моделей машинного обучения.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0fff3; padding: 15px; color: black; width: 80%;\"><b>Бэггинг</b> — это метод построения композиции моделей, в котором обучается несколько независимых моделей на случайных подмножествах обучающих данных с повторениями, а затем их предсказания усредняются для получения окончательного предсказания.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Бэггинг позволяет снизить дисперсию модели, т. к. усреднение предсказаний моделей позволяет уменьшить эффект переобучения.\n",
    "\n",
    "Примеры алгоритмов бэггинга: случайный лес и бэггинг деревьев решений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0fff3; padding: 15px; color: black; width: 80%;\"><b>Бустинг</b> — это метод построения композиции моделей, в котором последовательно обучаются модели, каждая из которых корректирует ошибки предыдущей модели на обучающих данных. Поэтому каждая следующая модель фокусируется на тех объектах, на которых предыдущие модели ошибались.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Бустинг позволяет снизить смещение модели, т. к. последующие модели корректируют ошибки предыдущих.\n",
    "\n",
    "Примеры алгоритмов бустинга: градиентный бустинг и AdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; padding: 15px; color: black; width: 80%;\">Общий подход при использовании бэггинга и бустинга заключается в создании ансамбля моделей, который является более точным, чем каждая из отдельных моделей. Однако бэггинг и бустинг имеют различные преимущества и недостатки, и выбор подхода зависит от специфики данных и задачи.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бэггинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В бэггинге (bootstrap aggregating) выбор случайных подмножеств объектов и признаков уменьшает корреляцию между отдельными моделями в композиции. Это позволяет снизить дисперсию композиции и сделать её более устойчивой к шуму."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_5_10.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбор случайного подмножества объектов происходит путём генерации новых выборок из исходного набора данных методом бутстрэпа (с повторениями). Каждый раз случайно выбирают подмножество объектов, которые используются для обучения отдельной модели. Количество объектов в каждом подмножестве также можно настроить как гиперпараметр.\n",
    "\n",
    "Выбор случайных подмножеств признаков (факторов) также можно применять в бэггинге для уменьшения корреляции между отдельными моделями. Однако, в отличие от выбора случайных подмножеств объектов, выбор случайных подмножеств признаков применяется на уровне отдельной модели, а не производится на каждом шаге генерации новых выборок.\n",
    "\n",
    "Случайные подмножества признаков можно выбирать различными способами: например, случайным выбором признаков на каждой вершине дерева при построении случайного леса или случайным выбором признаков при обучении каждой модели в композиции. Однако стоит помнить, что выбор подмножества признаков может негативно отразиться на качестве моделей, так как важность признаков неравнозначна, и следует применять его с осторожностью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0ffd1;color: black;border: 3px solid black; padding: 15px; margin-right: 500px; width: 80%;\">Выбор случайных подмножеств объектов или признаков — важная составляющая бэггинга. Он позволяет увеличить устойчивость композиции к шуму и повысить её точность. В машинном обучении устойчивость и качество работы моделей формализуются через понятия смещения и разброса. Давайте рассмотрим их.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Смещение и разброс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смещение и разброс — два ключевых понятия в машинном обучении, связанные с проблемой переобучения (overfitting) и недообучения (underfitting). Во многом это обобщение оценки недообучения и переобучения, в том числе для композиций моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0fff3; padding: 15px; color: black; width: 80%;\"><b>Смещение (bias)</b> — это ошибка модели, связанная с её недостаточной способностью улавливать реальную зависимость между признаками и целевой переменной. Модель с большим смещением может быть недообучена, т. е. её способность к обобщению данных будет низкой.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0fff3; padding: 15px; color: black; width: 80%;\"><b>Разброс (variance)</b> — это ошибка модели, связанная с её чрезмерной чувствительностью к случайным шумам в данных. Модель с большим разбросом может быть переобучена, т. е. она может слишком точно подстроиться под тренировочные данные и показывать плохие результаты на новых.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибку модели можно разложить на составляющие:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\text{Ошибка} = \\text{смещение}^2 + \\ \\text{разброс} + \\text{шум} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ", где:\n",
    "\n",
    "- смещение^2— квадрат ошибки модели, связанной с её недостаточной способностью улавливать реальную зависимость между признаками и целевой переменной;\n",
    "- разброс — ошибка модели, связанная с её чрезмерной чувствительностью к случайным шумам в данных;\n",
    "- шум — случайная ошибка, не поддающаяся объяснению моделью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смысл смещения и разброса модели показан на рисунке ниже:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_5_11.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trade-off между смещением и разбросом — это баланс между уменьшением ошибки модели, связанной со смещением, и ошибки модели, связанной с разбросом. Цель заключается в том, чтобы достичь оптимального уровня ошибки модели, который обеспечивает наилучшую способность к обобщению данных.\n",
    "\n",
    "-        Увеличение сложности модели может уменьшить смещение, но увеличить разброс, что может привести к переобучению.\n",
    "-        Уменьшение сложности модели может уменьшить разброс, но увеличить смещение, что может привести к недообучению.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_5_12.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бэггинг помогает уменьшить разброс за счёт использования нескольких случайных подмножеств обучающих данных и обучения независимых моделей на каждом из этих подмножеств. У каждой модели будут свои сильные и слабые стороны, что позволит уменьшить разброс в итоговой модели.\n",
    "\n",
    "С другой стороны, бэггинг не влияет на смещение, так как он всё ещё использует ту же функциональную форму модели на каждом подмножестве данных. Однако если в качестве базовых моделей для бэггинга используют решающие деревья, можно ожидать, что смещение также уменьшится. Это связано с тем, что решающие деревья могут описывать сложные зависимости в данных, а их комбинация позволяет учесть большее количество зависимостей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; padding: 15px; color: black; width: 80%;\">Подбор оптимальных параметров модели, например глубины дерева, позволяет найти баланс между смещением и разбросом, когда модель не переобучена и способна обобщать данные.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор оптимальных параметров дерева для нахождения баланса bias-variance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_5_13.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0ffd1;color: black;border: 3px solid black; padding: 15px; margin-right: 500px; width: 80%;\">При этом важно помнить, что если модели в композиции взаимосвязаны и ошибки одной модели могут быть связаны с ошибками другой модели, то использование бэггинга для уменьшения разброса может не дать значительного эффекта. Чем более связаны и похожи модели, тем меньший эффект оказывает бэггинг и тем больше разброса остаётся в композиции. Следовательно, для построения композиции моделей необходимо, чтобы базовые модели были максимально независимыми и отличными друг от друга.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, базовые модели также должны быть сложными, чтобы обеспечить достаточную гибкость для моделирования сложных зависимостей в данных. Эти требования к бэггингу реализованы в алгоритме случайного леса — о нём мы и поговорим далее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid white; padding: 5px; margin-right: auto;  width: 80%;\">В этом и предыдущем юнитах мы обсудили деревья решений и их композиции — давайте обозначим ключевые моменты.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0ffd1;color: black;border: 3px solid black; padding: 15px; margin-right: 500px; width: 80%;\">Одиночное решающее дерево имеет склонность к нестабильности, когда даже при небольшом изменении выборки предсказания модели значительно меняются. Для решения этой проблемы применяют композиции моделей, такие как бэггинг и бустинг.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бэггинг на деревьях (bagging of trees) — это метод ансамблирования, в котором используется множество независимых решающих деревьев для получения одной композиционной модели. Каждое дерево строится на основе выборки из обучающего набора данных, которая формируется случайным образом с повторениями. При формировании композиции каждое дерево получает равный вес в соответствии с принципом голосования. Бэггинг на деревьях помогает уменьшить разброс (variance) модели и повысить её устойчивость к выбросам.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0ffd1;color: black;border: 3px solid black; padding: 15px; margin-right: 500px; width: 80%;\">Смещение и разброс — два ключевых понятия в статистике и машинном обучении, которые связаны с ошибками предсказаний модели.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Смещение (bias) — это мера того, насколько среднее значение предсказаний модели отклоняется от правильных значений целевой переменной. Разброс (variance) — это мера того, насколько различаются предсказания модели для разных наблюдений из обучающей выборки.\n",
    "\n",
    "Идеальной моделью является та, у которой низкое смещение и низкий разброс. Однако уменьшение смещения может привести к увеличению разброса, а уменьшение разброса — к увеличению смещения. Поэтому при разработке модели важно найти баланс между смещением и разбросом."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
