{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dd-V-ELLKqrU"
   },
   "source": [
    "## Градиент\n",
    "\n",
    "Пусть $F(x, y, z)$ - функция трех переменных, $(x, y, z)$ - декартовы координаты.\n",
    "Градиентом функции $F(x, y, z)$ называется векторное поле\n",
    "$$\n",
    "\\nabla F(x, y, z)=\\frac{\\partial F}{\\partial x} \\mathbf{i}+\\frac{\\partial F}{\\partial y} \\mathbf{j}+\\frac{\\partial F}{\\partial z} \\mathbf{k}\n",
    "$$\n",
    "где $\\frac{\\partial F}{\\partial x}, \\frac{\\partial F}{\\partial y}$ и $\\frac{\\partial F}{\\partial z}-$ частные производные функции $F(x, y, z)$, а і, j и $\\mathbf{k}$ - базис декартовой системы координат $(x, y, z)$\n",
    "Иногда градиент обозначается так: $\\operatorname{grad} F(x, y, z)$.\n",
    "\n",
    "Главное свойство градиента – он показывает направление наискорейшего роста функции.\n",
    "\n",
    "**Пример**\n",
    "\n",
    "Найдите градиент функции $f(x, y)=x^{2}+y^{2}$ в точках $M(0,0), N(1,-1), P(1,1)$\n",
    "\n",
    "**Решение:**\n",
    "\n",
    "\n",
    "$\\frac{\\partial f}{\\partial x}=2 x \\quad \\frac{\\partial f}{\\partial y}=\\left.2 y \\quad \\quad \\quad \\quad \\quad \\operatorname{grad} f\\right|_{M}=\\left.(2 x, 2 y)\\right|_{x=0, y=0}=(0,0)$\n",
    "$$\n",
    "\\left.\\overrightarrow{g r a d} f\\right|_{N}=\\left.(2 x, 2 y)\\right|_{x=1, y=-1}=(2,-2)\n",
    "$$\n",
    "$\\overrightarrow{g r a d} f=\\left(\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}\\right)=\\left.(2 x, 2 y) \\quad \\quad \\quad \\quad \\quad \\operatorname{grad} f\\right|_{P}=\\left.(2 x, 2 y)\\right|_{x=1, y=1}=(2,2)$\n",
    "\n",
    "В точке $N$ градиент (2,-2) , то есть при увеличении $x$ функция $f$ будет возрастать, а при увеличении $y$ ー убывать. В точке $P$ значение градиента (2,2) , это значит что в окрестности $P$ наша сумма квадратов возрастает по обеим переменным. В точке $M$ градиент нулевой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KisBjKYCKqrV"
   },
   "source": [
    "**Что значит нулевой вектор градиента?**\n",
    "\n",
    "Смысл:\n",
    "* Все частные производные равны нулю.\n",
    "* Все касательные в точке $M$ горизонтальны.\n",
    "* $M$ — стационарная точка функции : максимум, минимум или седло (точка перегиба)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1UvsgPXKqra"
   },
   "source": [
    "## Градиентный спуск\n",
    "\n",
    "Градиентный спуск - это алгоритм оптимизации, используемый для поиска значений параметров (коэффициентов) функции (f), которая минимизирует функцию стоимости (cost).\n",
    "\n",
    "Градиентный спуск лучше всего использовать, когда параметры не могут быть вычислены аналитически (например, с использованием линейной алгебры) и должны быть найдены с помощью алгоритма оптимизации.\n",
    "\n",
    "Процедура начинается с начальных значений коэффициента или коэффициентов функции. Это может быть 0,0 или небольшое случайное значение.\n",
    "\n",
    "$$ \\text{коэффициент} = 0.0 $$\n",
    "\n",
    "Значение функции стоимости рассчитывается по формуле:\n",
    "\n",
    "$$ cost = f(\\text{коэффициент}) $$\n",
    "\n",
    "Рассчитывается производная стоимости. Производная - это понятие из математического анализа и относится к наклону функции в данной точке. Нам нужно знать наклон, чтобы знать направление (знак) для перемещения значений коэффициентов, чтобы снизить затраты на следующей итерации.\n",
    "\n",
    "$$ delta = \\text{производная}(cost) $$\n",
    "\n",
    "Теперь, когда мы знаем по производной, какое направление идет вниз, мы можем обновить значения коэффициентов. Необходимо указать параметр скорости обучения (альфа), который контролирует, насколько коэффициенты могут изменяться при каждом обновлении.\n",
    "\n",
    "$$ \\text{коэффициент} = \\text{коэффициент} – (alpha * delta)$$\n",
    "\n",
    "Этот процесс повторяется до тех пор, пока функция стоимости не станет 0 или достаточно близка к нулю, чтобы быть достаточно хорошей.\n",
    "\n",
    "Метод градиентного спуска требует, чтобы вы знали градиент вашей функции затрат или функции, которую вы оптимизируете. Далее мы увидим, как мы можем использовать это в алгоритмах машинного обучения.\n",
    "\n",
    "А сам алгоритм будет выглядеть примерно так:\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/600/1*iNPHcCxIvcm7RwkRaMTx1g.jpeg\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ld0xfDk4Kqrb"
   },
   "source": [
    "### Пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYhgexrHKqrc"
   },
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/3/32/Rosenbrock_function.svg\" width=400>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/a/a7/Rosenbrock_function.PNG\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROZS3ftQKqrd"
   },
   "source": [
    "Реализуем метод градиентного спуска на Python без использования библиотек. Посмотрим, как он ведёт себя при разных параметрах и критериях остановки.\n",
    "\n",
    "Оптимизировать будем **функцию Розенброка:**\n",
    "\n",
    "$f(x, y)=(1-x)^{2}+100\\left(y-x^{2}\\right)^{2}$\n",
    "\n",
    "Задаём функцию градиента, посчитав производные:\n",
    "\n",
    "$d x=2 x-2+100\\left(-4 y x+4 x^{3}\\right)$\n",
    "\n",
    "$d y=100\\left(2 y-2 x^{2}\\right)$\n",
    "\n",
    "Зададим параметры. Начальная точка (0, 0), γ = **0.1**, условием остановки зададим **20 000** итераций.\n",
    "\n",
    "Имплементируем формулу градиентного спуска:\n",
    "\n",
    "$x^{(n+1)}=x^{(n)}-\\gamma \\nabla f\\left(x^{(n)}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAnNc6z3Kqre"
   },
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return (1 - x) ** 2 + 100 * (y - x ** 2) ** 2\n",
    "\n",
    "def grad(x, y):\n",
    "    '''\n",
    "    dx = f'x\n",
    "    dy = f'y\n",
    "    '''\n",
    "    dx = 2 * x - 2 + 100 * (-4 * y * x + 4 * x ** 3)\n",
    "    dy = 100 * (2 * y - 2 * x ** 2)\n",
    "    return (dx, dy)\n",
    "\n",
    "def dist(x1, x2):\n",
    "    '''\n",
    "    x1 - 1st point like (x, y)\n",
    "    x2 - 2nd point like (x, y)\n",
    "    return ||x1-x2||_2^2\n",
    "    '''\n",
    "    return (x1[0] - x2[0]) ** 2 + (x1[1] - x2[1]) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZAG3AdOGKqrj",
    "outputId": "b35bd8b8-74f3-4b60-c6a4-9180a7fbb77c"
   },
   "outputs": [],
   "source": [
    "f(0,0), f(1,1), f(0,1), f(0,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4yCo9V0Kqrv",
    "outputId": "60f26b68-d084-429c-8ed6-ec6389d02555"
   },
   "outputs": [],
   "source": [
    "# where to start\n",
    "x0 = (0, 0)\n",
    "# learning rate\n",
    "gamma = 1e-3  # 0.001, 0.000001\n",
    "max_iter = 20000\n",
    "eps = 1e-12\n",
    "\n",
    "x_cur = x0\n",
    "vals = []\n",
    "coords = []\n",
    "i = 0\n",
    "\n",
    "while True:\n",
    "    # refresh points\n",
    "    x_new = (x_cur[0] - (gamma) * grad(*x_cur)[0],\n",
    "             x_cur[1] - (gamma) * grad(*x_cur)[1])\n",
    "\n",
    "    if dist(x_new, x_cur) < eps:  # check their change\n",
    "        print('\\ndist(x_new, x_cur) < eps')\n",
    "        break\n",
    "\n",
    "    x_cur = x_new\n",
    "    vals.append(f(*x_cur))  # append function value\n",
    "\n",
    "    coords.append(x_cur)  # append points\n",
    "    if i % 1000 == 0:  # count iterations\n",
    "        print(\n",
    "            f\"iter={i}; x=({x_cur[0]:.3f}, {x_cur[1]:.3f});\"\n",
    "            f\" f(x)={f(*x_cur):.2f}; grad f(x)=({grad(*x_cur)[0]:.3f}, {grad(*x_cur)[1]:.3f})\"\n",
    "        )\n",
    "    i += 1\n",
    "    if i > max_iter:\n",
    "        print('\\nmax iter reached')\n",
    "        break\n",
    "\n",
    "print()\n",
    "print(f'last iter = {i}')\n",
    "print(f'last x = {x_cur}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l33HrDTQKqr0",
    "outputId": "71beb877-0dc8-4cce-90de-03238d4f7020"
   },
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "optimize.minimize(lambda x: f(*x), x0=(0, 0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r22v-LHHKqsG"
   },
   "source": [
    "**Задание**\n",
    "- Найдите градиентным спуском минимум функции $f(x,y)=2 x^{2}-4 x y+y^{4}+2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RvtXrqa5KqsI"
   },
   "outputs": [],
   "source": [
    "def grad_descent(x0, f, grad, dist, gamma=1e-3, max_iter=20000, eps=1e-12):\n",
    "\n",
    "    x_cur = x0\n",
    "    vals = []\n",
    "    coords = []\n",
    "    i = 0\n",
    "\n",
    "    while True:\n",
    "        # refresh points\n",
    "        x_new = (x_cur[0] - (gamma) * grad(*x_cur)[0],\n",
    "                 x_cur[1] - (gamma) * grad(*x_cur)[1])\n",
    "\n",
    "        if dist(x_new, x_cur) < eps:  # check their change\n",
    "            print('\\ndist(x_new, x_cur) < eps')\n",
    "            break\n",
    "\n",
    "        x_cur = x_new\n",
    "        vals.append(f(*x_cur))  # append function value\n",
    "\n",
    "        coords.append(x_cur)  # append points\n",
    "        if i % 1000 == 0:  # count iterations\n",
    "            print(\n",
    "                f\"iter={i}; x=({x_cur[0]:.3f}, {x_cur[1]:.3f});\"\n",
    "                f\" f(x)={f(*x_cur):.2f}; grad f(x)=({grad(*x_cur)[0]:.3f}, {grad(*x_cur)[1]:.3f})\"\n",
    "            )\n",
    "        i += 1\n",
    "        if i > max_iter:\n",
    "            print('\\nmax iter reached')\n",
    "            break\n",
    "\n",
    "    print()\n",
    "    print(f'last iter = {i}')\n",
    "    print(f'last x = {x_cur}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1MasX5KGKqsN"
   },
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5bD47ruKqsS",
    "outputId": "9238b4aa-5ffd-4e75-cb52-b04c81d81da4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOzc3x2RKqsZ",
    "outputId": "cbbd2ba7-e480-407c-a793-610942165eae"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_60w76JuKqsn",
    "outputId": "ae076719-cf3f-4cac-a50b-d63d6a592c5b"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wh4FyQGlKqss",
    "outputId": "b435fa82-1a3b-459b-9717-220d3d6f8aa3"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Ed-KyuVKqs0",
    "outputId": "ba268a2d-c3ed-440d-a0aa-b652ae73bb87"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2sOMQ-0rKqs6",
    "outputId": "1a72b4a8-0e3d-49df-9190-294fadcdf6d8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJH8CtFFKqtC"
   },
   "source": [
    "### Пример\n",
    "\n",
    "Необходимо применить [SGDRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M91_fLOmKqtD"
   },
   "outputs": [],
   "source": [
    "#импорт необходимых библиотек и самого набора данных\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "WMgbG4AoKqtP",
    "outputId": "d3a9590e-5674-4be4-bd3c-1ebb17649b05"
   },
   "outputs": [],
   "source": [
    "df = sns.load_dataset('diamonds')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем информацию о датасете:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим колонки, с которыми не будем работать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['depth', 'table', 'x', 'y', 'z'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логарифмируем признаки со слишком разным диапазоном значений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['carat'] = np.log(1+df['carat'])\n",
    "df['price'] = np.log(1+df['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закодируем категориальные признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first=True) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую и тестовую выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "id": "8D1-bB8_Kqta",
    "outputId": "8a39de81-e78f-48b9-ad01-27e802f94ccb"
   },
   "outputs": [],
   "source": [
    "X_cols = [col for col in df.columns if col!='price'] \n",
    "X = df[X_cols]\n",
    "y = df['price']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CADaWWJzKqtn",
    "outputId": "170075c9-a038-42ff-aec4-6a04e6f3a149"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# your code here\n",
    "sgd = SGDRegressor(random_state=42)\n",
    "sgd.fit(X_train, y_train)\n",
    "sgd.score(X_train, y_train) #r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "31_ml_grad_descent_pt1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
