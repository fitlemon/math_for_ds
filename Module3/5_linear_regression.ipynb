{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid white; padding: 5px; margin-right: auto;  width: 80%;\"><b>Цель занятия</b> — знакомство с линейной регрессией — дифференцируемой моделью машинного обучения.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуальная демонстрация алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике достаточно часто встречаются ситуации линейной зависимости одной переменной от другой или других переменных. Линейную зависимость между двумя переменными можно вывести с помощью стандартных статистических методов, таких как корреляция.\n",
    "\n",
    "Если же целевая переменная зависит от нескольких признаков (в статистике их называют предикторами), используют более сложные модели. И первая из таких моделей — алгоритм линейной регрессии.\n",
    "\n",
    "Визуальная демонстрация алгоритма представлена на рисунке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_3_23.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На рисунке (1) приведена зависимость тормозного пути автомобиля от его скорости как пример построения линейной регрессии с одним признаком. Такая зависимость аппроксимируется линией и может быть визуализирована в двумерном пространстве. Алгоритм начинает поиск оптимального решения со случайных значений (синяя линия) и постепенно приближается к оптимальному значению (красная линия) — рисунок 2.\n",
    "\n",
    "Если в наборе данных содержится два признака, то оптимальные значения будут аппроксимироваться плоскостью в трехмерном пространстве — рисунок 3.\n",
    "\n",
    "В линейной регрессии мы вычисляем ошибку модели как расстояние между каждой точкой данных и гиперплоскостью, которая является аппроксимацией линейной связи между независимыми и зависимой переменными. Это расстояние измеряется вдоль нормали (или перпендикуляра) к гиперплоскости.\n",
    "\n",
    "Можно представить себе, что мы опускаем нормаль от каждой точки данных до гиперплоскости, получая расстояние между точкой данных и гиперплоскостью. Это расстояние называется <b>остаточной суммой (residual sum)</b> и является мерой того, насколько хорошо модель соответствует данным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; padding: 15px; color: black; width: 80%;\">В линейной регрессии мы стремимся минимизировать остаточную сумму, настраивая коэффициенты гиперплоскости таким образом, чтобы она была максимально близка к данным.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для модели с d-признаками (исключая свободный коэффициент), линейная регрессия аппроксимируется гиперплоскостью в (d+1)-мерном пространстве. Каждый признак умножается на соответствующий вес.\n",
    "\n",
    "Также в модель добавляется настраиваемый <b>свободный коэффициент</b> (b или w0), который позволяет модели не выдавать нулевой прогноз при нулевых значениях для остальных признаков. Для свободного коэффициента обычно добавляется «фиктивный признак», все значения которого равны 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; padding: 15px; color: black; width: 80%;\">Предсказание модели в таком случае — это скалярное произведение вектора весов на вектор признаков, изображенное на рисунке (4). Оно демонстрирует математическую суть линейной регрессии — в двумерном случае линейная регрессия задается хорошо известным еще со школы уравнением прямой.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_3_24.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание алгоритма\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдем от визуального описания алгоритма линейной регрессии к примеру его использования и формальному определению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0fff3; padding: 15px; color: black; width: 80%;\">  Линейная регрессия с несколькими признаками, также называемая множественной линейной регрессией, — это метод анализа данных, который позволяет определить линейную зависимость между целевой (зависимой) переменной и несколькими признаками (независимыми переменными).</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что вы хотите определить, какие факторы влияют на цену на недвижимость. В этом случае зависимой переменной будет цена на недвижимость, а независимыми переменными могут быть такие факторы, как площадь квартиры, количество комнат, расстояние до ближайшего метро, возраст здания и т. д.\n",
    "\n",
    "Множественная линейная регрессия позволяет определить, как каждый из этих факторов влияет на цену недвижимости, и как их комбинация может объяснить изменения цен на рынке недвижимости.\n",
    "\n",
    "Например, если мы построим модель множественной линейной регрессии для цен на недвижимость, используя площадь квартиры, количество комнат и расстояние до ближайшего метро как независимые переменные, то мы можем получить следующее уравнение:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цена = 5000 + 100 * Площадь + 2000 * Комнаты — 500 * Расстояние"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уравнении коэффициент перед каждой независимой переменной (площадью, количеством комнат и расстоянием до ближайшего метро) показывает, как каждая из этих переменных влияет на цену на недвижимость.\n",
    "\n",
    "Например, увеличение площади квартиры на 1 кв. метр приведет к увеличению цены на 100 единиц, увеличение количества комнат на 1 приведет к увеличению цены на 2000 единиц, а увеличение расстояния до ближайшего метро на 1 км приведет к уменьшению цены на 500 единиц.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; padding: 15px; color: black; width: 80%;\">Таким образом, множественная линейная регрессия позволяет определить, как каждый из факторов влияет на зависимую переменную, а также как их комбинация влияет на изменения цен на рынке недвижимости.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дадим формальное определение линейной регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0fff3; padding: 15px; color: black; width: 80%;\">  <b>Линейная регрессия</b> — это метод машинного обучения, который используется для оценки линейной зависимости между набором признаков (независимых переменных) и целевой (зависимой) переменной. Линейная регрессия позволяет найти линейную функцию, которая наилучшим образом описывает зависимость между признаками и целевой переменной.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Математически линейная регрессия определяется следующим образом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_3_25.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных для алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Перед применением алгоритма линейной регрессии необходимо выполнить следующие шаги подготовки данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0fff3; padding: 15px; color: black; width: 80%;\">  <b>Очистка данных</b> включает удаление неполных или некорректных записей, заполнение пропущенных значений и преобразование данных в формат, подходящий для анализа.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0fff3; padding: 15px; color: black; width: 80%;\">  <b>Нормализация данных</b> — это приведение данных к общему масштабу, чтобы каждый признак имел одинаковый вклад в анализ.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормирование признаков является важным шагом в предобработке данных перед использованием линейной регрессии. Это связано с тем, что линейная регрессия оценивает веса (коэффициенты) каждого признака в модели, чтобы предсказать целевую переменную. Если масштабы разных признаков значительно отличаются друг от друга, то оценка весов может быть смещена в сторону признаков с большими значениями. Это может привести к неверным выводам и плохому качеству предсказания.\n",
    "\n",
    "Обычно используются два основных способа нормирования:\n",
    "\n",
    "-    Стандартизация. Признаки масштабируются так, чтобы их среднее значение было равно 0, а стандартное отклонение было равно 1.\n",
    "-    Нормализация. Признаки масштабируются так, чтобы их значения находились в диапазоне от 0 до 1.\n",
    "\n",
    "После нормирования признаков каждый из них будет иметь примерно одинаковый вклад в предсказание целевой переменной, что позволит линейной регрессии более точно оценивать их веса и делать более точные прогнозы.\n",
    "\n",
    "<b>Разбиение данных на обучающую и тестовую выборки</b>. Обучающая выборка используется для обучения модели, а тестовая выборка — для оценки ее точности.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Процесс обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения этой задачи используются аналитическое решение и метод градиентного спуска. Результатом обучения модели линейной регрессии является набор оптимальных значений весов и смещения , которые могут быть использованы для предсказания целевой переменной для новых наблюдений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аналитическое решение линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует аналитическое решение для линейной регрессии:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_3_26.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_3_27.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Причины неприменимости нормального уравнения:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_3_28.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный спуск повторяется до тех пор, пока значение функции ошибки не перестанет существенно изменяться или пока не будет достигнуто максимальное количество итераций.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0fff3; padding: 15px; color: black; width: 80%;\">  Использование градиентного спуска для оптимизации линейной регрессии имеет некоторые преимущества: возможность работать с большими объемами данных и возможность настройки гиперпараметров, таких как скорость обучения.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_3_29.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки качества алгоритма линейной регрессии часто используют следующие метрики:\n",
    "\n",
    "-    <b>Mean Squared Error (MSE)</b> — средняя квадратичная ошибка между прогнозами и истинными значениями.\n",
    "-    <b>Mean Absolute Error (MAE)</b> — средняя абсолютная ошибка между прогнозами и истинными значениями.\n",
    "-    <b>Huber loss — комбинация MSE и MAE</b>, которая более устойчива к выбросам в данных, чем MSE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Интерпретация признаков с помощью алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интерпретация признаков в линейной регрессии заключается в понимании того, как каждый признак влияет на зависимую переменную в модели. Это помогает понять, какие признаки наиболее важны для прогнозирования целевой переменной и как они с ней связаны.\n",
    "\n",
    "Наиболее простой способ оценить влияние того или иного признака — посмотреть на весовой коэффициент при признаке. Коэффициенты признаков в линейной регрессии представляют величину и направление влияния каждого признака на зависимую переменную."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; padding: 15px; color: black; width: 80%;\">Если значение признака большое, можно сказать, что его значение также большое (при условии нормализованных данных). Если коэффициент положительный, то увеличение значения признака будет приводить к увеличению значения зависимой переменной. Если коэффициент отрицательный, то увеличение значения признака будет приводить к уменьшению значения зависимой переменной.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модификации алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует несколько модификаций алгоритма линейной регрессии, которые могут быть применены в зависимости от задачи и данных.\n",
    "\n",
    "Некоторые из них:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- <b>    Ridge regression (гребневая регрессия) </b>— добавление регуляризации L2 в функцию потерь для борьбы с переобучением. Это позволяет уменьшить веса модели, чтобы она была менее склонна к переобучению и более устойчива к шуму в данных.\n",
    "- <b>    Lasso regression (лассо-регрессия) </b>— добавление регуляризации L1 в функцию потерь, чтобы стимулировать разреженность весов модели. Это означает, что некоторые веса будут установлены на ноль, что может помочь идентифицировать наиболее важные признаки.\n",
    "- <b>    Elastic Net</b> — комбинация L1 и L2 регуляризации в функции потерь. Это позволяет улучшить баланс между разреженностью и устойчивостью к шуму.\n",
    "- <b>    Polynomial regression (полиномиальная регрессия)</b> — расширение линейной регрессии путем добавления полиномиальных признаков для учета нелинейных зависимостей между признаками и целевой переменной.\n",
    "- <b>  Robust regression (робастная регрессия) </b>— модификация линейной регрессии, которая более устойчива к выбросам в данных. Она использует альтернативные функции потерь, такие как Huber loss, которые уменьшают вклад выбросов в обучении модели.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Область применения алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия — один из самых простых и наиболее распространенных методов машинного обучения, и может быть применена во многих областях.\n",
    "\n",
    "Например:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- <b>   Финансовый анализ</b>. Линейная регрессия может использоваться для прогнозирования цен акций, доходности инвестиций и других финансовых показателей.\n",
    "-<b>    Маркетинг</b>. Линейная регрессия может использоваться для анализа данных о продажах и прогнозирования спроса на товары и услуги.\n",
    "- <b>    Медицинская статистика</b>. Линейная регрессия может использоваться для анализа данных о заболеваемости и смертности, прогнозирования риска развития заболеваний и определения факторов, влияющих на здоровье.\n",
    "- <b>    Инженерия</b>. Линейная регрессия может использоваться для анализа данных в различных областях, таких как электроника, механика и транспорт, для прогнозирования характеристик и поведения систем.\n",
    "- <b>    Социальные науки</b>. Линейная регрессия может использоваться для анализа социальных данных, таких как опросы общественного мнения, для прогнозирования выборов, определения влияния социальных факторов на поведение людей и т. д.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; padding: 15px; color: black; width: 80%;\">В целом, линейная регрессия может быть использована для анализа любых данных, для которых есть зависимость между одной или несколькими признаками и целевой переменной. Однако следует учитывать, что линейная регрессия может быть неэффективной для данных с нелинейными зависимостями и слабыми связями между переменными.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Плюсы и минусы алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "😃\n",
    "\n",
    "\n",
    "\n",
    "-    Простота реализации и понимания — это один из самых простых алгоритмов машинного обучения.\n",
    "-    Может использоваться для задач регрессии и оценки влияния признаков.\n",
    "-    Эффективен на больших выборках и может быстро обучаться на большом количестве признаков.\n",
    "-    Хорошо интерпретируется и может помочь понять важность каждого признака.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "😟\n",
    "\n",
    "-    Чувствительность к выбросам и шуму в данных.\n",
    "-    Требует выполнения предположения о линейной зависимости между признаками и целевой переменной, что может быть проблематично в некоторых случаях.\n",
    "-    Не учитывает взаимодействие между признаками, что может привести к недооценке важности некоторых признаков.\n",
    "-    Может быть склонен к переобучению, если в модели слишком много признаков или коэффициенты признаков сильно отличаются друг от друга.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; padding: 15px; color: black; width: 80%;\">В целом, алгоритм линейной регрессии также имеет простую и понятную логику, но его эффективность может быть низкой в случае шумных данных и если не выполняются предположения о линейной зависимости между признаками и целевой переменной.</div>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
