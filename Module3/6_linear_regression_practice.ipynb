{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Цель занятия\n",
    "На этом занятии мы рассмотрим реализацию различных алгоритмов линейной регрессии в sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека Scikit-learn предоставляет несколько реализаций линейной регрессии. Рассмотрим отличия между ними:\n",
    "\n",
    "- **LinearRegression:** это стандартная реализация линейной регрессии. Она использует метод наименьших квадратов (МНК), чтобы оценить коэффициенты регрессии. Эта реализация подходит для задач с небольшим количеством признаков, но может быть неэффективной, если признаков много, так как МНК требует обращения матрицы.\n",
    "\n",
    "- **Lasso:** это регуляризованная версия линейной регрессии, которая использует L1-регуляризацию для уменьшения коэффициентов регрессии. Это позволяет не только уменьшить переобучение, но также выполнить отбор признаков путем установки значений коэффициентов ненужных признаков равными нулю.\n",
    "\n",
    "- **Ridge:** это регуляризованная версия линейной регрессии, которая использует L2-регуляризацию для уменьшения коэффициентов регрессии. Это позволяет уменьшить переобучение модели и улучшить ее обобщающую способность.\n",
    "\n",
    "- **ElasticNet:** это регуляризованная версия линейной регрессии, которая сочетает L1- и L2-регуляризацию. Это позволяет улучшить обобщающую способность модели и выполнить отбор признаков, одновременно уменьшая коэффициенты регрессии.\n",
    "\n",
    "- **SGDRegressor:** это стохастическая реализация линейной регрессии, которая использует градиентный спуск для оценки коэффициентов регрессии. Она может быть эффективной для задач с большим количеством признаков, так как не требует обращения матрицы.\n",
    "\n",
    "- **HuberRegressor:** это реализация линейной регрессии, которая минимизирует функцию потерь Хьюбера, которая более устойчива к выбросам, чем функция потерь MSE.\n",
    "\n",
    "- **PassiveAggressiveRegressor:** это реализация линейной регрессии, которая использует алгоритм пассивного агрессивного обучения (PA), который может быть эффективным для обучения на больших объемах данных в режиме онлайн.\n",
    "\n",
    "- **TheilSenRegressor:** это реализация линейной регрессии, которая использует метод Theil-Sen для оценки коэффициентов регрессии. Он является более устойчивым к выбросам, чем MSE, но может быть менее точным в случае отсутствия выбросов.\n",
    "\n",
    "Каждая реализация линейной регрессии имеет свои преимущества и недостатки, и выбор подходящей модели зависит от характеристик задачи и данных. Например, если в задаче много признаков, то может быть более эффективно использовать регуляризованные версии линейной регрессии, а если в данных есть выбросы, то можно использовать реализации, более устойчивые к ним."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Используемые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load_diabetes - это встроенный датасет в библиотеке Scikit-learn, содержащий информацию о 442 пациентах \n",
    "с диабетом, собранную в период с 1984 по 1988 годы в США. Датасет состоит из 11 признаков и одного целевого \n",
    "значения.\n",
    "\n",
    "Каждый признак представляет собой некоторый медицинский показатель, который может быть связан с диабетом. \n",
    "Признаки включают возраст пациента, пол, среднее артериальное давление, уровень сывороточного холестерина, \n",
    "уровень глюкозы в крови и другие.\n",
    "\n",
    "Целевое значение представляет собой показатель прогрессирования заболевания диабетом год спустя после начала \n",
    "наблюдений, измеряемый в количественных единицах. В датасете целевое значение называется \"target\".\n",
    "\n",
    "Набор данных load_diabetes содержит следующие параметры:\n",
    "\n",
    "age: Возраст пациента.\n",
    "sex: Пол пациента.\n",
    "bmi: Индекс массы тела (Body Mass Index) пациента.\n",
    "bp: Артериальное давление пациента.\n",
    "s1, s2, s3, s4, s5, s6: 6 различных биохимических показателей крови, измеренных у пациента.\n",
    "target: Количество прогрессирования диабета, измеряемое по шкале здоровья.\n",
    "\"\"\"\n",
    "\n",
    "params_names = [\"age\", \"sex\", \"bmi\", \"bp\", \"s1\", \"s2\", \"s3\", \"s4\", \"s5\", \"s6\"]\n",
    "\n",
    "# Загрузка набора данных диабета\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "# Разбивка данных на обучающий и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка mse Lasso регрессии: 3383.5084900141464\n",
      "age: -0.0\n",
      "sex: -164.61625659281296\n",
      "bmi: 558.3655524091124\n",
      "bp: 244.76051417965422\n",
      "s1: -105.69577720946631\n",
      "s2: -0.0\n",
      "s3: -219.7690107077367\n",
      "s4: 0.0\n",
      "s5: 533.341275685286\n",
      "s6: 7.383606229419217\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "В этом примере мы работаем с набором данных диабета, \n",
    "создаем объект модели Lasso с коэффициентом регуляризации alpha равным 0.1, \n",
    "обучаем модель на обучающем наборе данных, оцениваем mse модели на тестовом наборе данных, \n",
    "выводим оценку mse Lasso регрессии.\n",
    "\"\"\"\n",
    "\n",
    "# Создание объекта модели Lasso\n",
    "lasso = linear_model.Lasso(alpha=0.1)\n",
    "\n",
    "# Обучение модели на обучающем наборе данных\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Оценка модели на тестовом наборе данных\n",
    "y_pred = lasso.predict(X_test)\n",
    "\n",
    "# Оценка модели по метрике mse\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Вывод mse оценки модели\n",
    "print(\"Оценка mse Lasso регрессии:\", mse)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Коэффициенты модели можно использовать для определения важности признаков. \n",
    "Высокие значения коэффициентов указывают на более важные признаки.\n",
    "\"\"\"\n",
    "\n",
    "# Оценка модели на тестовом наборе данных\n",
    "score = lasso.score(X_test, y_test)\n",
    "\n",
    "# Вывод коэффициентов модели\n",
    "for param_name, coef in zip(params_names, lasso.coef_):\n",
    "    print(f\"{param_name}: {coef}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка mse Ridge регрессии: 3372.6122501751975\n",
      "age: -18.93029239015494\n",
      "sex: -205.95750389040967\n",
      "bmi: 520.8856039771601\n",
      "bp: 278.43533925964505\n",
      "s1: -81.87766380450014\n",
      "s2: -108.9616339354653\n",
      "s3: -209.97654964833913\n",
      "s4: 117.75990964121306\n",
      "s5: 457.61641721160345\n",
      "s6: 69.0037365871282\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Здесь мы создаем объект модели Ridge, обучаем модель на обучающем наборе данных, \n",
    "оцениваем ее на тестовом наборе данных, вычисляем метрику MSE и выводим ее оценку. \n",
    "Затем мы выводим коэффициенты модели и их важность, используя тот же цикл for, что и для модели Lasso.\n",
    "\"\"\"\n",
    "\n",
    "# Создание объекта модели Ridge\n",
    "ridge = linear_model.Ridge(alpha=0.1)\n",
    "\n",
    "# Обучение модели на обучающем наборе данных\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Оценка модели на тестовом наборе данных\n",
    "y_pred = ridge.predict(X_test)\n",
    "\n",
    "# Оценка модели по метрике mse\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Вывод mse оценки модели\n",
    "print(\"Оценка mse Ridge регрессии:\", mse)\n",
    "\n",
    "# Оценка модели на тестовом наборе данных\n",
    "score = ridge.score(X_test, y_test)\n",
    "\n",
    "# Вывод коэффициентов модели\n",
    "for param_name, coef in zip(params_names, ridge.coef_):\n",
    "    print(f\"{param_name}: {coef}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка mse ElasticNet регрессии: 4666.423151304215\n",
      "age: 10.35155390455935\n",
      "sex: 0.0\n",
      "bmi: 40.831344827091925\n",
      "bp: 27.502937600389807\n",
      "s1: 10.801546452328875\n",
      "s2: 7.26882202657813\n",
      "s3: -26.474810755863928\n",
      "s4: 27.14333968649607\n",
      "s5: 38.461427329283644\n",
      "s6: 23.783601854861644\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Здесь мы создаем объект модели ElasticNet с коэффициентом регуляризации alpha равным 0.1 и коэффициентом \n",
    "смешивания L1 и L2 регуляризации l1_ratio равным 0.5. Затем мы обучаем модель на обучающем наборе данных, \n",
    "оцениваем mse модели на тестовом наборе данных, выводим оценку mse ElasticNet регрессии и коэффициенты модели, \n",
    "которые указывают на важность признаков.\n",
    "\"\"\"\n",
    "\n",
    "# Создание объекта модели ElasticNet\n",
    "elastic_net = linear_model.ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "\n",
    "# Обучение модели на обучающем наборе данных\n",
    "elastic_net.fit(X_train, y_train)\n",
    "\n",
    "# Оценка модели на тестовом наборе данных\n",
    "y_pred = elastic_net.predict(X_test)\n",
    "\n",
    "# Оценка модели по метрике mse\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Вывод mse оценки модели\n",
    "print(\"Оценка mse ElasticNet регрессии:\", mse)\n",
    "\n",
    "# Оценка модели на тестовом наборе данных\n",
    "score = elastic_net.score(X_test, y_test)\n",
    "\n",
    "# Вывод коэффициентов модели\n",
    "for param_name, coef in zip(params_names, elastic_net.coef_):\n",
    "    print(f\"{param_name}: {coef}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка mse SGDRegressor: 4980.8129495299145\n",
      "age: 4.29516300087018\n",
      "sex: 0.7423683448888175\n",
      "bmi: 13.87934045994235\n",
      "bp: 8.89014808869358\n",
      "s1: 3.7574526406159445\n",
      "s2: 2.877160073156542\n",
      "s3: -8.999722672940338\n",
      "s4: 9.107253725202385\n",
      "s5: 12.291858421535277\n",
      "s6: 7.791387747699137\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "В примере с SGDRegressor мы будем использовать функцию partial_fit(), \n",
    "которая позволяет обучать модель по мини-батчам. Это полезно для больших наборов данных, \n",
    "которые не могут поместиться в памяти целиком.\n",
    "\"\"\"\n",
    "\n",
    "# Создание объекта модели SGDRegressor\n",
    "sgd = linear_model.SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "\n",
    "# Обучение модели на частях обучающего набора данных\n",
    "batch_size = 20\n",
    "n_batches = len(X_train) // batch_size\n",
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        X_batch = X_train[start:end]\n",
    "        y_batch = y_train[start:end]\n",
    "        sgd.partial_fit(X_batch, y_batch)\n",
    "\n",
    "# Оценка модели на тестовом наборе данных\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "# Оценка модели по метрике mse\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Вывод mse оценки модели\n",
    "print(\"Оценка mse SGDRegressor:\", mse)\n",
    "\n",
    "# Вывод коэффициентов модели\n",
    "for param_name, coef in zip(params_names, sgd.coef_):\n",
    "    print(f\"{param_name}: {coef}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Data Wrangling & EDA with Pandas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
