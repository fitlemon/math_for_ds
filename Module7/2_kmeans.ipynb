{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель занятия — изучить алгоритм k-средних (k-means)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуальная демонстрация алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0fff3; padding: 15px; color: black; width: 80%;\">  <b>K-средних (k-means)</b> — это один из наиболее распространённых методов кластеризации, используемых в машинном обучении и анализе данных. Этот алгоритм разбивает набор данных на заранее заданное количество кластеров. Каждый кластер представляет группу объектов, которые схожи между собой и отличаются от объектов в других кластерах.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На рисунках ниже показан процесс обучения k-means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_7_12.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_7_13.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Этапы обучения k-means:</b>\n",
    "\n",
    "1.    Выбираем случайные центры для каждого кластера.\n",
    "2.   Относим каждую точку к ближайшему кластеру на основе расстояния до центров кластеров.\n",
    "3.    Пересчитываем центры кластеров, используя среднее арифметическое точек, принадлежащих кластеру.\n",
    "4.    Когда центры кластеров обновлены, повторяем процесс перераспределения точек по кластерам и обновления центров.\n",
    "\n",
    "Этот итеративный процесс повторяется до тех пор, пока центры кластеров и распределение точек не стабилизируются или не будут достигнуты заранее заданные условия остановки.\n",
    "\n",
    "Алгоритм k-means пытается минимизировать сумму квадратов расстояний между точками и центрами кластеров, что приводит к тому, что точки внутри каждого кластера становятся более близкими друг к другу, а точки между разными кластерами остаются далёкими друг от друга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных для алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общий процесс подготовки данных для использования с алгоритмом k-средних:\n",
    "\n",
    "1.    Масштабирование данных. Рекомендуется масштабировать признаки входных данных перед применением k-средних, особенно если признаки имеют различные шкалы или единицы измерения. Обычно для приведения данных к общей шкале используется стандартизация или нормализация.\n",
    "2.    Удаление выбросов. Выбросы могут негативно влиять на процесс кластеризации. Перед применением алгоритма k-средних рекомендуется удалить или скорректировать выбросы в данных.\n",
    "3.    Работа с категориальными переменными. Если в данных есть категориальные переменные, необходимо преобразовать их в числовой формат. Для этого можно использовать One-Hot Encoding или Label Encoding.\n",
    "4.   Обработка пропущенных значений. Если в данных есть пропущенные значения, в зависимости от контекста данных нужно либо удалить строки или столбцы с пропущенными значениями, либо заполнить их средними или медианными значениями.\n",
    "5.    Отбор признаков. Если признаков много, для кластеризации важно выбрать из них наиболее релевантные и информативные. Для этого можно использовать методы отбора признаков или снижения размерности данных: анализ главных компонент (PCA) или методы выбора признаков на основе значимости.\n",
    "6.    Обработка корреляций. Если между признаками есть сильные корреляции, это может повлиять на работу алгоритма k-средних. Рекомендуется проанализировать корреляции и решить, какие признаки оставить, исключить или объединить в один признак.\n",
    "7.    Учёт особенностей данных. Если в данных есть особенности, такие как выборки с несбалансированным размером кластеров или шум, следует учесть эти особенности при выборе количества кластеров и интерпретации результатов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Процесс обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея алгоритма k-means заключается в том, чтобы минимизировать сумму квадратов ошибок (Sum of Squared Errors), то есть отклонения между объектами внутри кластеров и их центроидами.\n",
    "\n",
    "Сумма квадратов ошибок представлена следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_7_14.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уравнении мы вычисляем квадрат расстояния между каждой точкой данных $ x_{ij}$ и соответствующим ей центроидом $ c_j$ для всех точек данных и кластеров. Затем суммируем эти квадраты расстояний, чтобы получить SSE.\n",
    "\n",
    "Выбрать оптимальное количество кластеров в алгоритме k-means может быть сложно — давайте рассмотрим некоторые методы, которые позволяют это сделать.\n",
    "\n",
    "<b>Метод локтя (elbow method)</b> заключается в вычислении суммы квадратов ошибок (SSE) для различных значений числа кластеров и выборе значения, при котором увеличение числа кластеров не приводит к существенному снижению SSE.\n",
    "\n",
    "График зависимости SSE от числа кластеров имеет форму локтя, и оптимальное число кластеров соответствует точке, где SSE перестаёт значительно уменьшаться.\n",
    "\n",
    "<b>Коэффициент силуэта (silhouette coefficient) </b>используют для оценки качества кластеризации. Он учитывает среднее расстояние между объектами внутри кластера и среднее расстояние до ближайшего соседнего кластера.\n",
    "\n",
    "Значение коэффициента силуэта находится в диапазоне от -1 до 1, где более близкое к 1 значение указывает на хорошее качество кластеризации. Оптимальное количество кластеров можно выбрать на основе максимального значения коэффициента силуэта.\n",
    "\n",
    "<b>Метод gap statistic</b> сравнивает значения SSE для фактических данных с ожидаемыми значениями SSE на случайной выборке. Чем больше разница между фактическими и ожидаемыми значениями SSE, тем лучше модель кластеризации. Оптимальное количество кластеров выбирают на основе максимального значения gap между фактическими и ожидаемыми значениями SSE.\n",
    "\n",
    "<b>Экспертные знания</b>. Иногда экспертные знания о предметной области могут помочь в выборе оптимального количества кластеров. Если вы знакомы с данными и ожидаете определённое количество групп или паттернов, вы можете использовать это знание для выбора числа кластеров.\n",
    "\n",
    "Важно отметить, что выбор оптимального числа кластеров является относительным и может зависеть от конкретной задачи и данных. Рекомендуется использовать несколько методов оценки и сравнить результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До сходимости алгоритм выполняет следующие шаги:\n",
    "\n",
    "1.    Инициализация. Выбираются случайные центроиды для каждого из кластеров. Центроид представляет собой точку в пространстве признаков, которая является центром кластера.\n",
    "2.    Присваивание кластера. Каждый объект из набора данных присваивается ближайшему центроиду. Близость обычно измеряется с использованием евклидового расстояния, но можно использовать и другие метрики.\n",
    "3.    Обновление центроидов. Расчёт нового центроида для каждого кластера путём вычисления среднего значения всех объектов, принадлежащих к данному кластеру.\n",
    "\n",
    "Шаги 2–3 повторяются до тех пор, пока не будет достигнут критерий сходимости: например, пока изменение центроидов не станет незначительным или когда количество итераций достигнет заранее определённого предела."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценить качество работы алгоритма k-средних (k-means) можно с помощью нескольких метрик и методов. Перечислим наиболее распространённые способы оценки.\n",
    "\n",
    "<b>Сумма квадратов ошибок (SSE)</b> — метрика, которая измеряет сумму квадратов расстояний между каждой точкой данных и центроидом её кластера. Меньшее значение SSE указывает на лучшую кластеризацию. Однако SSE — не нормализованная метрика и может зависеть от выбранного числа кластеров.\n",
    "\n",
    "<b>Коэффициент силуэта (silhouette coefficient)</b> — метрика, которая оценивает, насколько каждая точка данных соответствует собственному кластеру по сравнению с другими кластерами. Коэффициент силуэта принимает значения от -1 до 1, где значение ближе к 1 указывает на хорошую кластеризацию, а ближе к -1 — на неправильную кластеризацию.\n",
    "\n",
    "<b>Индекс Дэвиса — Болдина (Davies–Bouldin Index)</b> — это индекс, который измеряет среднюю схожесть и различие между кластерами. Меньшее значение индекса указывает на лучшую кластеризацию.\n",
    "\n",
    "<b>Внутрикластерное расстояние и межкластерное расстояние</b>. Можно также посмотреть на внутрикластерное расстояние (среднее расстояние между точками внутри кластера) и межкластерное расстояние (среднее расстояние между центроидами кластеров). Хорошая кластеризация должна иметь маленькое внутрикластерное расстояние и большое межкластерное расстояние.\n",
    "\n",
    "<b>Визуализация результатов</b>. Визуализация кластеров может помочь визуально оценить качество работы алгоритма k-средних. Например, можно построить диаграмму рассеяния (Scatter plot) и отобразить точки данных в пространстве признаков, окрашивая их в соответствии с принадлежностью кластерам.\n",
    "\n",
    "Пример визуального анализа с помощью диаграмм рассеяния:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_7_9.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм k-средних (k-means) имеет широкий спектр применений в различных областях:\n",
    "\n",
    "-    Кластерный анализ и сегментация данных. K-средних широко используют для кластеризации данных и сегментации на группы схожих объектов. Это можно применять в маркетинге для сегментации клиентов на основе их предпочтений и поведения, в анализе данных для группировки схожих наблюдений и в биоинформатике для классификации геномных данных.\n",
    "-    Обработка изображений. K-средних можно применять для сегментации изображений, разделения пикселей на группы в соответствии с их цветом или текстурой. Это может быть полезно в распознавании образов, компьютерном зрении или сжатии изображений.\n",
    "-    Рекомендательные системы. В области рекомендательных систем k-средних можно использовать для группировки пользователей или элементов в схожие кластеры. Это позволяет создавать персонализированные рекомендации, исходя из поведения или предпочтений пользователей.\n",
    "-    Анализ текстовых данных. K-средних можно использовать для анализа текстовых данных, например для кластеризации документов по схожести содержания или группировки слов в тематические кластеры.\n",
    "-    Геоинформационные системы. В геоинформационных системах k-средних можно применять для кластеризации пространственных данных, таких как точки на карте или географические регионы. Это может быть полезно для анализа распределения объектов, обнаружения паттернов или планирования маршрутов.\n",
    "-    Обнаружение аномалий. K-средних можно использовать для обнаружения аномальных наблюдений в данных. Аномальные точки можно удалить или выделить в отдельные кластеры, что помогает в идентификации необычных событий или аномалий в различных областях, таких как финансы, кибербезопасность или медицинская диагностика.\n",
    "\n",
    "Это только несколько примеров областей применения алгоритма k-средних. Его можно использовать во многих других сферах, где требуется кластеризация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Плюсы и минусы алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Плюсы:</b>\n",
    "\n",
    "-    Простота реализации и понимания. K-средних — простой и интуитивно понятный алгоритм. Он основан на принципе минимизации суммы квадратов ошибок (SSE) и легко реализуется с помощью итеративного процесса.\n",
    "-    Высокая эффективность. K-средних имеет высокую вычислительную эффективность, особенно при больших объёмах данных. Он может обрабатывать большие наборы данных относительно быстро и масштабируется для работы с большим количеством точек данных.\n",
    "-    Масштабируемость. Алгоритм k-средних хорошо масштабируется с увеличением количества кластеров или объёма данных. Его можно применять для различных задач кластеризации, начиная от небольшого числа кластеров.\n",
    "-    Применимость к широкому спектру данных. K-средних можно использовать для различных типов данных, включая числовые, категориальные и даже текстовые. Алгоритм не зависит от распределения данных и может работать с разными типами признаков.\n",
    "-    Интерпретируемость результатов. Результаты k-средних можно легко интерпретировать и визуализировать. Кластеры, сформированные алгоритмом, представляют собой группы схожих объектов, что помогает понять структуру данных и выявить паттерны.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Минусы:</b>\n",
    "\n",
    "-    Чувствительность к выбору начальных центроидов. Результаты k-средних могут сильно зависеть от исходного выбора центроидов. Неправильная инициализация может привести к сходимости к локальному, а не к глобальному оптимальному решению. Может потребоваться много раз запускать алгоритм с разными начальными условиями.\n",
    "-    Зависимость от количества кластеров. Пользователь должен заранее определить количество кластеров k, что может быть сложной задачей. Неправильный выбор значения k может привести к неправильной кластеризации или объединению несхожих групп в один кластер.\n",
    "-    Предположение о выпуклости кластеров. Алгоритм k-средних предполагает, что кластеры являются выпуклыми. Если данные имеют сложную форму или кластеры имеют различные формы и размеры, k-средних может давать неправильные результаты.\n",
    "-    Чувствительность к выбросам. K-средних чувствителен к выбросам в данных. Одиночные точки-выбросы могут сильно повлиять на положение центроидов и привести к искажению кластеризации.\n",
    "-    Нет гарантии глобального оптимума. Алгоритм k-средних может сойтись к локальному оптимуму, особенно при сложной структуре данных или плохой инициализации. В некоторых случаях для достижения лучших результатов могут потребоваться более сложные алгоритмы кластеризации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means реализован в библиотеке sklearn. Чтобы его использовать, необходимо предварительно импортировать <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\">класс KMeans</a> из модуля sklearn.cluster.\n",
    "\n",
    "Основные параметры:\n",
    "\n",
    "    n_clusters — количество кластеров, которое требуется найти. Это обязательный параметр, его необходимо указать при создании объекта KMeans.\n",
    "    init — метод инициализации начальных центроидов. Может принимать значения k-means++, random или массив начальных центроидов. По умолчанию используется метод k-means++. Он позволяет более равномерно распределить начальные центроиды по набору данных, что помогает избежать попадания в локальные минимумы и улучшает качество кластеризации.\n",
    "    n_init — количество запусков алгоритма с различными начальными центроидами. По умолчанию n_init=10.\n",
    "    max_iter — максимальное количество итераций для сходимости алгоритма. По умолчанию max_iter=300.\n",
    "    tol — порог сходимости алгоритма. Если изменение SSE (суммы квадратов ошибок) между двумя последовательными итерациями меньше tol, алгоритм прекращает работу. По умолчанию tol=1e-4.\n",
    "\n",
    "Класс KMeans также имеет методы fit(X) — для обучения модели на данных X, predict(X) — для присвоения меток кластеров новым данным X, transform(X) — для преобразования данных X в матрицу расстояний до центроидов.\n",
    "\n",
    "<b>Давайте резюмируем</b>.\n",
    "\n",
    "K-means — это простой и популярный алгоритм кластеризации, который позволяет разделить набор данных на группы (кластеры) на основе схожести данных.\n",
    "\n",
    "-    K-means итеративно присваивает точки ближайшим центроидам и обновляет центроиды до сходимости.\n",
    "-    Алгоритм стремится минимизировать внутрикластерную сумму квадратов ошибок (SSE), которая измеряет сумму квадратов расстояний между точками и соответствующими центроидами.\n",
    "-    K-means требует заранее заданное количество кластеров (k). Выбор оптимального значения k — важная задача при использовании k-means.\n",
    "-    Качество работы алгоритма можно оценить с помощью метрик, таких как коэффициент силуэта или индекс Дэвиса — Болдина.\n",
    "-    K-means можно применять в различных областях: анализ данных, сегментация клиентов, обработка изображений и мн. др. Однако k-means имеет свои ограничения — чувствительность к начальной инициализации и форме кластеров, а также предположение о выпуклых кластерах и равной дисперсии.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
