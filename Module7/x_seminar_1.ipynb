{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Цель занятия\n",
    "На этом занятии мы рассмотрим особенности реализации алгоритмов кластеризации и снижения размерности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means (к-средних) — это алгоритм кластеризации, который используется для разделения набора данных на группы (кластеры) на основе их схожести. Алгоритм старается минимизировать суммарное квадратичное отклонение между точками внутри каждого кластера и центроидами (средними значениями) этих точек.\n",
    "\n",
    "Процесс работы алгоритма k-средних следующий:\n",
    "\n",
    "1. Инициализация: Выбирается количество кластеров k и случайно инициализируются k центроидов.\n",
    "2. Присваивание точек к кластерам: Каждая точка данных присваивается к ближайшему центроиду на основе евклидова расстояния или другой метрики.\n",
    "3. Пересчет центроидов: Вычисляются новые центроиды путем нахождения средних значений точек в каждом кластере.\n",
    "4. Повторение шагов 2 и 3: Шаги 2 и 3 повторяются до сходимости алгоритма, то есть до тех пор, пока точки перестают изменять свою принадлежность к кластерам или достигнут предел максимального количества итераций.\n",
    "\n",
    "В результате работы алгоритма k-средних мы получаем k кластеров, в каждом из которых точки схожи между собой и отличаются от точек в других кластерах. Кластеризация данных с помощью k-средних может быть полезна для группировки и классификации данных, выявления скрытых закономерностей и понимания структуры данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X, K, max_iters=100):\n",
    "    # Инициализация центроидов случайным образом\n",
    "    centroids = X[np.random.choice(range(len(X)), K, replace=False)]\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        # Нахождение ближайшего центроида для каждой точки\n",
    "        labels = np.argmin(np.linalg.norm(X[:, np.newaxis] - centroids, axis=-1), axis=-1)\n",
    "        \n",
    "        # Обновление центроидов\n",
    "        new_centroids = np.array([X[labels == k].mean(axis=0) for k in range(K)])\n",
    "        \n",
    "        # Проверка условия сходимости\n",
    "        if np.all(centroids == new_centroids):\n",
    "            break\n",
    "        \n",
    "        centroids = new_centroids\n",
    "    \n",
    "    return centroids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Центроиды:\n",
      "[[1.16666667 1.46666667]\n",
      " [7.33333333 9.        ]]\n",
      "Метки кластеров:\n",
      "[0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Пример использования\n",
    "X = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 11]])\n",
    "K = 2\n",
    "\n",
    "centroids, labels = kmeans(X, K)\n",
    "print(\"Центроиды:\")\n",
    "print(centroids)\n",
    "print(\"Метки кластеров:\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "\n",
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) - это алгоритм кластеризации данных, основанный на плотности. Он идентифицирует кластеры, исходя из плотности точек в пространстве данных, а также обнаруживает выбросы, которые не принадлежат ни к одному кластеру.\n",
    "\n",
    "Процесс работы алгоритма DBSCAN следующий:\n",
    "\n",
    "1. Выбор начальной точки: Выбирается случайная точка, которая еще не была посещена и не является выбросом.\n",
    "2. Поиск плотной области: Алгоритм расширяется от выбранной начальной точки, посещая ближайшие точки в заданном радиусе epsilon. Если в заданной окрестности (эпсилон-окрестности) находится минимальное количество точек, необходимое для формирования кластера, то точка считается ядром (core point).\n",
    "3. Расширение кластера: Для каждого ядра образуется кластер, который включает все точки, достижимые из этого ядра в заданном радиусе epsilon. Для этого рекурсивно ищутся все плотные точки в окрестности ядра.\n",
    "4. Поиск выбросов: Точки, которые не достижимы из ядерных точек, считаются выбросами (noise points). Они не принадлежат ни к одному кластеру.\n",
    "5. Повторение шагов 2-4: Шаги 2-4 повторяются для всех непосещенных точек данных до тех пор, пока все точки не будут просмотрены.\n",
    "\n",
    "В результате работы алгоритма DBSCAN получаем кластеры различной формы и размеров. Кластеры определяются на основе плотности точек в пространстве данных, а не на основе евклидова расстояния. Это позволяет DBSCAN обнаруживать кластеры произвольной формы и корректно обрабатывать выбросы. Алгоритм DBSCAN может быть особенно полезен в задачах, где кластеры имеют различную плотность или форму, или когда необходимо обнаружить выбросы и шум в данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBSCAN:\n",
    "    def __init__(self, eps, min_samples):\n",
    "        self.eps = eps\n",
    "        self.min_samples = min_samples\n",
    "        self.labels = None\n",
    "    \n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.labels = np.zeros(len(X))  # Инициализируем массив меток кластера нулями для каждой точки в датасете\n",
    "        cluster_label = 0  # Инициализируем счетчик меток кластера\n",
    "\n",
    "        for i in range(len(X)):  # Проходим по всем точкам в датасете\n",
    "            if self.labels[i] != 0:  # Если точка уже имеет метку кластера, переходим к следующей точке\n",
    "                continue\n",
    "\n",
    "            neighbors = self._find_neighbors(X, i)  # Находим соседей для текущей точки\n",
    "\n",
    "            if len(neighbors) < self.min_samples:  # Если количество соседей меньше минимального требования\n",
    "                self.labels[i] = -1  # Присваиваем точке метку выброса (-1)\n",
    "            else:\n",
    "                cluster_label += 1  # Инкрементируем счетчик меток кластера\n",
    "                self._expand_cluster(X, i, neighbors, cluster_label)  # Расширяем кластер, начиная с текущей точки\n",
    "\n",
    "    \n",
    "    def _expand_cluster(self, X, point_index, neighbors, cluster_label):\n",
    "        \"\"\"\n",
    "        В этом методе сначала присваивается выбранной точке `point_index` метка кластера `cluster_label`.\n",
    "\n",
    "        Затем идет цикл `while`, который выполняется, пока не исчерпаны все соседи в списке `neighbors`.\n",
    "\n",
    "        На каждой итерации цикла берется очередной сосед из списка `neighbors` и проверяется его метка кластера:\n",
    "\n",
    "        - Если метка равна `-1`, это означает, что сосед не имеет метки кластера. \n",
    "            В этом случае ему присваивается метка кластера `cluster_label`.\n",
    "        - Если метка равна `0`, это означает, что сосед не принадлежит ни одному кластеру. \n",
    "            В этом случае ему также присваивается метка кластера `cluster_label`. \n",
    "        Затем для этого соседа находятся новые соседи с помощью метода `_find_neighbors`.\n",
    "            - Если количество новых соседей больше или равно минимальному требованию `min_samples`, \n",
    "                то эти новые соседи добавляются в список `neighbors`.\n",
    "\n",
    "        В конце каждой итерации цикла инкрементируется счетчик `i` для перехода к следующему \n",
    "        соседу в списке `neighbors`.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.labels[point_index] = cluster_label  # Присваиваем метку кластера выбранной точке\n",
    "\n",
    "        i = 0\n",
    "        while i < len(neighbors):  # Пока не исчерпаны все соседи\n",
    "            neighbor = neighbors[i]  # Берем очередного соседа\n",
    "\n",
    "            if self.labels[neighbor] == -1:  # Если сосед не имеет метки кластера\n",
    "                self.labels[neighbor] = cluster_label  # Присваиваем ему метку кластера\n",
    "            elif self.labels[neighbor] == 0:  # Если сосед не принадлежит ни одному кластеру\n",
    "                self.labels[neighbor] = cluster_label  # Присваиваем ему метку кластера\n",
    "                new_neighbors = self._find_neighbors(X, neighbor)  # Находим новых соседей для данной точки\n",
    "\n",
    "                if len(new_neighbors) >= self.min_samples:  # Если количество новых соседей больше или равно минимальному требованию\n",
    "                    neighbors += new_neighbors  # Добавляем новых соседей в список соседей\n",
    "            i += 1  # Переходим к следующему соседу\n",
    "\n",
    "    \n",
    "    def _find_neighbors(self, X, point_index):\n",
    "        # Инициализируем пустой список для хранения индексов соседних точек\n",
    "        neighbors = []  \n",
    "        for i in range(len(X)):  # Проходим по всем точкам в датасете\n",
    "            # Если расстояние между текущей точкой и точкой с индексом i меньше или равно eps\n",
    "            if self.euclidean_distance(X[point_index], X[i]) <= self.eps:  \n",
    "                neighbors.append(i)  # Добавляем индекс соседней точки в список neighbors\n",
    "        return neighbors  # Возвращаем список соседних точек\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метки кластеров:\n",
      "[ 1.  1. -1. -1.  1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# Пример использования\n",
    "X = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 11]])\n",
    "eps = 2\n",
    "min_samples = 2\n",
    "\n",
    "dbscan = DBSCAN(eps, min_samples)\n",
    "dbscan.fit(X)\n",
    "\n",
    "print(\"Метки кластеров:\")\n",
    "print(dbscan.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Агломеративная кластеризация\n",
    "\n",
    "Агломеративная кластеризация (агломеративный метод) - это алгоритм иерархической кластеризации, который последовательно объединяет близкие точки данных в кластеры, формируя дерево иерархии кластеров, называемое дендрограммой.\n",
    "\n",
    "Процесс работы агломеративной кластеризации следующий:\n",
    "\n",
    "1. Инициализация: Каждая точка данных начинает в качестве отдельного кластера.\n",
    "2. Вычисление матрицы расстояний: Вычисляется матрица расстояний между каждой парой кластеров. Расстояние может быть определено различными способами, такими как евклидово расстояние или корреляция.\n",
    "3. Объединение ближайших кластеров: Два ближайших кластера (т.е. с наименьшим расстоянием между ними) объединяются в один новый кластер.\n",
    "4. Обновление матрицы расстояний: Матрица расстояний обновляется, чтобы отразить расстояния между новым объединенным кластером и остальными кластерами.\n",
    "5. Повторение шагов 3 и 4: Шаги 3 и 4 повторяются до тех пор, пока все точки данных не объединятся в один кластер или достигнется заранее заданное количество кластеров.\n",
    "6. Построение дендрограммы: На основе последовательности объединений строится дендрограмма, которая визуализирует иерархию кластеров.\n",
    "\n",
    "Результат агломеративной кластеризации представляет собой дерево иерархии кластеров, где каждый узел представляет собой кластер, а расстояние между узлами отображает степень их схожести. По анализу дендрограммы можно определить оптимальное количество кластеров, а также их структуру и иерархические отношения. Агломеративная кластеризация особенно полезна в задачах, где требуется иерархическое представление кластеров или когда количество кластеров неизвестно заранее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgglomerativeClustering:\n",
    "    def __init__(self, n_clusters):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.labels = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        # Инициализация каждой точки как отдельного кластера\n",
    "        clusters = [[x] for x in X]\n",
    "\n",
    "        while len(clusters) > self.n_clusters:  # Пока количество кластеров больше заданного числа\n",
    "            min_dist = np.inf  # Инициализация минимального расстояния как бесконечность\n",
    "            merge_indices = (0, 0)  # Инициализация индексов кластеров для объединения\n",
    "\n",
    "            # Находим два ближайших кластера для объединения\n",
    "            for i in range(len(clusters)):  # Проходим по каждому кластеру\n",
    "                for j in range(i+1, len(clusters)):  # Проходим по остальным кластерам\n",
    "                    dist = self._distance(clusters[i], clusters[j])  # Вычисляем расстояние между кластерами\n",
    "\n",
    "                    if dist < min_dist:  # Если текущее расстояние меньше минимального\n",
    "                        min_dist = dist  # Обновляем значение минимального расстояния\n",
    "                        merge_indices = (i, j)  # Обновляем индексы кластеров для объединения\n",
    "\n",
    "            # Объединяем два ближайших кластера\n",
    "            merged_cluster = clusters[merge_indices[0]] + clusters[merge_indices[1]]\n",
    "\n",
    "            # Удаляем объединенные кластеры из списка\n",
    "            del clusters[merge_indices[1]]\n",
    "            del clusters[merge_indices[0]]\n",
    "\n",
    "            # Добавляем объединенный кластер в список\n",
    "            clusters.append(merged_cluster)\n",
    "\n",
    "        # Присваиваем метки кластеров точкам\n",
    "        self.labels = self._assign_labels(clusters, X)\n",
    "\n",
    "    \n",
    "    def _distance(self, cluster1, cluster2):\n",
    "        min_dist = np.inf  # Инициализируем переменную минимального расстояния как бесконечность\n",
    "\n",
    "        for point1 in cluster1:  # Проходим по каждой точке в первом кластере\n",
    "            for point2 in cluster2:  # Проходим по каждой точке во втором кластере\n",
    "                dist = np.linalg.norm(point1 - point2)  # Вычисляем Евклидово расстояние между двумя точками\n",
    "                if dist < min_dist:  # Если текущее расстояние меньше минимального\n",
    "                    min_dist = dist  # Обновляем значение минимального расстояния\n",
    "\n",
    "        return min_dist  # Возвращаем минимальное расстояние\n",
    "\n",
    "    \n",
    "    def _assign_labels(self, clusters, dataset):\n",
    "        labels = np.zeros(dataset.shape[0], dtype=int)  # Заполняем для каждой точки массив меток нулями\n",
    "\n",
    "        for index, point in enumerate(dataset):  # Проходим по каждой  точке в датасете\n",
    "            for cluster_index, cluster in enumerate(clusters): # Проходим по всем кластерам\n",
    "                if np.sum(np.all(cluster == point, axis=1)): # Проверяем вхождение точки в текущий кластер\n",
    "                    labels[index] = cluster_index  # Присваиваем метку кластера текущей точке\n",
    "                    continue\n",
    "\n",
    "        return labels  # Возвращаем массив меток\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метки кластеров:\n",
      "[0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Пример использования\n",
    "X = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 11]])\n",
    "n_clusters = 2\n",
    "\n",
    "agglomerative = AgglomerativeClustering(n_clusters)\n",
    "agglomerative.fit(X)\n",
    "\n",
    "print(\"Метки кластеров:\")\n",
    "print(agglomerative.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA \n",
    "\n",
    "PCA(Principal Component Analysis) - это метод снижения размерности данных, который используется для выявления наиболее информативных признаков в наборе данных и проекции их на новое пространство меньшей размерности. Основная цель PCA - найти линейные комбинации исходных признаков, называемые главными компонентами, которые содержат наибольшую дисперсию в данных.\n",
    "\n",
    "Процесс работы PCA следующий:\n",
    "\n",
    "1. Стандартизация данных: Исходные признаки стандартизируются, чтобы они имели среднее значение равное 0 и стандартное отклонение равное 1. Это делается для того, чтобы признаки с различными единицами измерения не искажали результаты анализа.\n",
    "2. Вычисление матрицы ковариации: Вычисляется матрица ковариации, которая показывает связи исходных признаков друг с другом. Ковариация измеряет, насколько два признака меняются вместе.\n",
    "3. Вычисление собственных значений и собственных векторов: Собственные значения и собственные векторы извлекаются из матрицы ковариации. Собственные значения представляют собой меру дисперсии вдоль соответствующих собственных векторов.\n",
    "4. Сортировка главных компонент: Главные компоненты сортируются по убыванию их собственных значений. Главная компонента с наибольшим собственным значением содержит наибольшую дисперсию в данных.\n",
    "5. Выбор количества главных компонент: Определяется количество главных компонент, которые будут использоваться для проекции данных на новое пространство. Можно выбрать определенное количество компонент или определить процент дисперсии, которую они объясняют.\n",
    "6. Проекция данных: Исходные признаки проецируются на выбранные главные компоненты, формируя новое пространство с меньшей размерностью.\n",
    "\n",
    "Результат PCA - это новое пространство признаков с меньшей размерностью, где каждая главная компонента представляет собой линейную комбинацию исходных признаков. Главные компоненты упорядочены по убыванию их значимости, и первые компоненты содержат наибольшую долю дисперсии в данных. PCA широко используется для визуализ\n",
    "\n",
    "ации данных, устранения мультиколлинеарности, сжатия данных и улучшения производительности алгоритмов машинного обучения путем снижения размерности пространства признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "        self.components = None\n",
    "        self.mean = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        # Вычисляем среднее значение каждого признака\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        \n",
    "        # Центрируем данные путем вычитания среднего\n",
    "        X_centered = X - self.mean\n",
    "        \n",
    "        # Вычисляем матрицу ковариации\n",
    "        covariance_matrix = np.cov(X_centered.T)\n",
    "        \n",
    "        # Вычисляем собственные значения и собственные векторы\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "        \n",
    "        # Сортируем собственные значения и соответствующие собственные векторы в порядке убывания\n",
    "        eigen_indices = np.argsort(eigenvalues)[::-1]\n",
    "        sorted_eigenvectors = eigenvectors[:, eigen_indices]\n",
    "        \n",
    "        # Выбираем первые n_components собственных векторов\n",
    "        self.components = sorted_eigenvectors[:, :self.n_components]\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Центрируем данные путем вычитания среднего\n",
    "        X_centered = X - self.mean\n",
    "        \n",
    "        # Проецируем данные на главные компоненты\n",
    "        transformed = np.dot(X_centered, self.components)\n",
    "        \n",
    "        return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Преобразованные данные:\n",
      "[[-7.79422863e+00 -2.77555756e-16]\n",
      " [-2.59807621e+00  5.55111512e-17]\n",
      " [ 2.59807621e+00 -5.55111512e-17]\n",
      " [ 7.79422863e+00  2.77555756e-16]]\n"
     ]
    }
   ],
   "source": [
    "# Пример использования\n",
    "X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
    "n_components = 2\n",
    "\n",
    "pca = PCA(n_components)\n",
    "pca.fit(X)\n",
    "\n",
    "transformed = pca.transform(X)\n",
    "print(\"Преобразованные данные:\")\n",
    "print(transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE \n",
    "\n",
    "t-SNE (t-Distributed Stochastic Neighbor Embedding) - это метод снижения размерности данных, который используется для визуализации сложных структур данных и обнаружения скрытых паттернов. В отличие от PCA, t-SNE обеспечивает сохранение не только линейной структуры данных, но и нелинейных отношений между точками.\n",
    "\n",
    "Процесс работы t-SNE следующий:\n",
    "\n",
    "1. Вычисление аффинности: Сначала вычисляется аффинность (похожесть) между парами точек данных. Это может быть сделано с использованием Гауссовой функции, основанной на расстоянии между точками в исходном пространстве.\n",
    "2. Вычисление условной вероятности: Для каждой точки данных вычисляется условная вероятность, которая показывает вероятность выбрать другую точку в качестве соседа, исходя из аффинности. Более похожие точки имеют более высокие вероятности быть выбранными в качестве соседей.\n",
    "3. Определение сходства в пространстве низкой размерности: Для пространства низкой размерности (обычно 2D) исходные точки данных и их аффинности переопределяются с использованием условных вероятностей. Это позволяет сохранить близость точек, имеющих высокую аффинность в исходном пространстве.\n",
    "4. Минимизация дивергенции Кульбака-Лейблера: t-SNE оптимизирует распределение точек в пространстве низкой размерности, минимизируя дивергенцию Кульбака-Лейблера между условными вероятностями точек в исходном пространстве и пространстве низкой размерности.\n",
    "5. Итерационная оптимизация: Алгоритм итеративно обновляет расположение точек в пространстве низкой размерности, чтобы минимизировать дивергенцию Кульбака-Лейблера. Оптимизация основывается на градиентных методах или методах случайного блуждания.\n",
    "\n",
    "Результат t-SNE представляет собой вложение точек в пространство низкой размерности, где близкие точки соответствуют точкам с высокой аффинностью в исходном пространстве. t-SNE обладает способностью выявлять сложные нелинейные структуры и класт\n",
    "\n",
    "еры в данных, что делает его полезным для визуализации и понимания сложных наборов данных. Однако важно отметить, что расположение точек в пространстве низкой размерности может быть чувствительным к различным параметрам и инициализации, поэтому результаты t-SNE требуют внимательного анализа и интерпретации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSNE:\n",
    "    def __init__(self, n_components, perplexity=30, learning_rate=200, n_iter=1000, use_history=False):\n",
    "        self.n_components = n_components\n",
    "        self.perplexity = perplexity\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iter = n_iter\n",
    "        self.embedding = None\n",
    "        self.use_history = use_history\n",
    "        self.history = []\n",
    "    \n",
    "    def fit(self, X):\n",
    "        np.random.seed(0)  # Установка начального состояния генератора случайных чисел\n",
    "        self.embedding = np.random.normal(0, 1e-4, (X.shape[0], self.n_components))\n",
    "        # Инициализация матрицы вложений с помощью случайных значений из нормального распределения\n",
    "\n",
    "        pairwise_distances = self._pairwise_distances(X)  # Вычисление попарных расстояний между точками\n",
    "\n",
    "        P = self._compute_conditional_probabilities(pairwise_distances)\n",
    "        # Вычисление матрицы условных вероятностей P на основе попарных расстояний\n",
    "\n",
    "        Y = np.random.normal(0, 1e-4, (X.shape[0], self.n_components))\n",
    "        # Инициализация матрицы Y с помощью случайных значений из нормального распределения\n",
    "\n",
    "        for _ in range(self.n_iter):\n",
    "            Q = self._compute_joint_probabilities(Y)  # Вычисление матрицы совместных вероятностей Q\n",
    "            grad = self._gradient(P, Q, Y)  # Вычисление градиента\n",
    "            Y = Y - self.learning_rate * grad  # Обновление матрицы Y с помощью градиентного спуска\n",
    "            if self.use_history:\n",
    "                self.history.append(Y)\n",
    "\n",
    "        self.embedding = Y  # Присваивание полученных вложений матрице self.embedding\n",
    "\n",
    "\n",
    "    \n",
    "    def _pairwise_distances(self, X):\n",
    "        sum_X = np.sum(np.square(X), axis=1)  # Вычисление суммы квадратов элементов по строкам матрицы X\n",
    "        pairwise_distances = np.add(np.add(-2 * np.dot(X, X.T), sum_X).T, sum_X)\n",
    "        # Вычисление попарных евклидовых расстояний между точками:\n",
    "        # - Вычисление произведения матрицы X на транспонированную матрицу X и умножение его на -2.\n",
    "        # - Добавление суммы квадратов элементов по строкам матрицы X к полученной матрице.\n",
    "        # - Транспонирование матрицы и добавление суммы квадратов элементов по строкам матрицы X к каждому столбцу.\n",
    "\n",
    "        pairwise_distances = np.maximum(pairwise_distances, 0)  # Замена отрицательных значений на нули\n",
    "\n",
    "        return pairwise_distances  # Возвращение матрицы попарных расстояний\n",
    "\n",
    "\n",
    "    \n",
    "    def _compute_conditional_probabilities(self, distances):\n",
    "        P = np.zeros((distances.shape[0], distances.shape[0]))  # Инициализация матрицы условных вероятностей P\n",
    "\n",
    "        for i in range(distances.shape[0]):\n",
    "            sorted_indices = np.argsort(distances[i])[1:self.perplexity+1]  # Индексы k ближайших соседей, отсортированных по возрастанию расстояния\n",
    "            Di = distances[i, sorted_indices]  # Расстояния до k ближайших соседей\n",
    "            Hi = self._binary_search_perplexity(Di)  # Вычисление условной вероятности Hi на основе бинарного поиска perplexity\n",
    "            P[i, sorted_indices] = Hi  # Присваивание найденных условных вероятностей Hi в соответствующие ячейки матрицы P\n",
    "\n",
    "        P = (P + P.T) / (2 * distances.shape[0])  # Симметризация матрицы P и нормализация\n",
    "        P = np.maximum(P, 1e-12)  # Устранение нулевых значений и сглаживание\n",
    "\n",
    "        return P  # Возвращение матрицы условных вероятностей P\n",
    "\n",
    "    \n",
    "    def _binary_search_perplexity(self, Di):\n",
    "        beta = 1.0  # Инициализация параметра бета для двоичного поиска\n",
    "        desired_entropy = np.log2(self.perplexity)  # Желаемая энтропия, вычисленная на основе perplexity\n",
    "        min_beta = -np.inf  # Минимальное значение бета\n",
    "        max_beta = np.inf  # Максимальное значение бета\n",
    "        tolerance = 1e-5  # Допустимая погрешность\n",
    "\n",
    "        for _ in range(50):\n",
    "            sum_Pi = np.sum(np.exp(-beta * Di))  # Сумма условных вероятностей Pi\n",
    "            Hi = np.log2(sum_Pi) + beta * np.sum(Di * np.exp(-beta * Di)) / sum_Pi\n",
    "            # Вычисление энтропии Hi на основе текущего значения бета:\n",
    "            # - Вычисляем сумму экспонент -beta * Di и записываем ее в sum_Pi.\n",
    "            # - Вычисляем Hi путем сложения логарифма sum_Pi и выражения beta * np.sum(Di * np.exp(-beta * Di)) / sum_Pi.\n",
    "\n",
    "            entropy_diff = Hi - desired_entropy  # Разница между текущей и желаемой энтропией\n",
    "\n",
    "            if np.abs(entropy_diff) <= tolerance:\n",
    "                break  # Если разница между энтропиями меньше или равна допустимой погрешности, выходим из цикла\n",
    "\n",
    "            if entropy_diff > 0:\n",
    "                max_beta = beta  # Если разница положительная, ограничиваем максимальное значение бета\n",
    "                if np.isinf(min_beta):\n",
    "                    beta *= 2  # Если минимальное значение бета равно отрицательной бесконечности, удваиваем бета\n",
    "                else:\n",
    "                    beta = (beta + min_beta) / 2  # Иначе, вычисляем новое значение бета как среднее между текущим и минимальным значением бета\n",
    "            else:\n",
    "                min_beta = beta  # Если разница отрицательная, ограничиваем минимальное значение бета\n",
    "                if np.isinf(max_beta):\n",
    "                    beta /= 2  # Если максимальное значение бета равно положительной бесконечности, делаем бета в два раза меньше\n",
    "                else:\n",
    "                    beta = (beta + max_beta) / 2  # Иначе, вычисляем новое значение бета как среднее между текущим и максимальным значением бета\n",
    "\n",
    "        return np.exp(-beta * Di)  # Возвращаем условную вероятность Pi, вычисленную на основе окончательного значения бета\n",
    "\n",
    "\n",
    "    \n",
    "    def _compute_joint_probabilities(self, Y):\n",
    "        sum_Y = np.sum(np.square(Y), axis=1)  # Сумма квадратов координат точек в низкоразмерном пространстве\n",
    "        pairwise_distances = np.add(np.add(-2 * np.dot(Y, Y.T), sum_Y).T, sum_Y)\n",
    "        # Расстояния между точками в низкоразмерном пространстве.\n",
    "        # -2 * np.dot(Y, Y.T) вычисляет скалярное произведение между всеми парами точек в низкоразмерном пространстве.\n",
    "        # Суммируя сумму квадратов координат исходных точек (sum_Y), получаем расстояния.\n",
    "\n",
    "        pairwise_distances = np.maximum(pairwise_distances, 1e-12)  # Предотвращение деления на ноль\n",
    "\n",
    "        Q = 1 / pairwise_distances  # Вычисление совместной вероятности Q\n",
    "        np.fill_diagonal(Q, 0)  # Установка нулей на диагонали, чтобы исключить вероятности точек самих с собой\n",
    "        Q /= np.sum(Q)  # Нормализация вероятностей, чтобы их сумма составляла 1\n",
    "\n",
    "        return Q  # Возвращаем совместную вероятность Q\n",
    "\n",
    "    \n",
    "    def _gradient(self, P, Q, Y):\n",
    "\n",
    "        n = len(P)\n",
    "        gradient = np.zeros(shape=(n, Y.shape[1]))\n",
    "        for i in range(0, n):\n",
    "            # Разница между координатами текущей точки Y[i] и всеми остальными точками Y\n",
    "            diff = Y[i] - Y\n",
    "            # Разница между матрицами условных вероятностей P[i] и совместной вероятности Q[i]\n",
    "            A = np.array([(P[i, :] - Q[i, :])])\n",
    "            # Вычисление значения B, используя расстояния между точками в низкоразмерном пространстве\n",
    "            B = np.array([(1 + np.linalg.norm(diff, axis=1))**(-1)])\n",
    "            # Разница между координатами текущей точки Y[i] и всеми остальными точками Y\n",
    "            C = diff\n",
    "            # Вычисление градиента для текущей точки\n",
    "            gradient[i] = 4 * np.sum((A * B).T * C, axis=0)\n",
    "\n",
    "        return gradient\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Пример использования\n",
    "X = np.array([[1, 1, 1], [2, 2, 2], [7, 7, 7], [8, 8, 8]])\n",
    "y_true = np.array([0,0,1,1])\n",
    "n_components = 2\n",
    "\n",
    "tsne = TSNE(n_components, use_history=True)\n",
    "tsne.fit(X)\n",
    "\n",
    "embedding = tsne.embedding\n",
    "x = embedding[:, 0]  # Извлечение координаты X для каждой точки\n",
    "y = embedding[:, 1]  # Извлечение координаты Y для каждой точки\n",
    "\n",
    "plt.scatter(x, y, c=y_true)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Диаграмма рассеяния')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Data Wrangling & EDA with Pandas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
