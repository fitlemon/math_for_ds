{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Цель занятия — изучить алгоритм t-SNE для решения задач снижения размерности на подготовленных и неподготовленных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0fff3; padding: 15px; color: black; width: 80%;\">  <b>t-SNE (t-Distributed Stochastic Neighbor Embedding)</b> — это алгоритм машинного обучения, используемый для визуализации и снижения размерности данных. Он был разработан для отображения сложных многомерных данных в двух- или трёхмерное пространство с сохранением сходства между точками.</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея t-SNE заключается в том, чтобы представить исходные данные в новом пространстве, где близкие объекты остаются близкими, а далёкие объекты разделяются. Алгоритм строит вероятностное распределение для пар объектов в исходном и новом пространствах таким образом, чтобы минимизировать разницу между ними. Также t-SNE позволяет учитывать локальные и глобальные структуры данных.\n",
    "\n",
    "Алгоритм t-SNE широко используется в визуализации данных, особенно при работе с высокоразмерными и сложными наборами данных, такими как изображения или тексты. Он помогает обнаруживать скрытые паттерны, кластеры и взаимосвязи между объектами в данных.\n",
    "\n",
    "Перед тем как рассмотреть t-SNE, необходимо освежить в памяти некоторые понятия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0fff3; padding: 15px; color: black; width: 80%;\">  <b>Нормальное распределение (распределение Гаусса)</b> — одно из наиболее распространённых и важных вероятностных распределений. Оно характеризуется плотностью вероятности, которая имеет форму колокола или симметричного колоколообразного графика.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_7_36.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формула плотности вероятности нормального распределения выглядит следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ f(x)=\\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\cdot e^{-\\frac{(x-\\mu)^2}{2 \\sigma^2}} $\n",
    "<br>\n",
    "где:\n",
    "\n",
    "$ x $    — случайная переменная; <br>\n",
    "$ \\mu $    — математическое ожидание (среднее значение) распределения;<br>\n",
    "$ \\sigma ^2 $    — дисперсия (квадрат стандартного отклонения) распределения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой формуле параметры $ \\mu $ и $ \\sigma ^2 $ определяют положение и форму колокола нормального распределения. Математическое ожидание $\\mu $ указывает на центр колокола, а дисперсия $ \\sigma ^2 $ определяет его ширину."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0fff3; padding: 15px; color: black; width: 80%;\">  <b>Распределение Стьюдента (t-распределение)</b> — это вероятностное распределение. Оно широко используется при оценке параметров и проведении статистических тестов в малых выборках, когда исходная генеральная совокупность имеет нормальное распределение, но значение дисперсии неизвестно.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение Стьюдента с параметром $ v $ , обозначаемое как $ t(v) $, имеет форму колокола с симметричным графиком вокруг нуля. Число степеней свободы определяет форму $v $ распределения и влияет на его «хвостатость». Чем больше $v $, тем ближе распределение Стьюдента приближается к стандартному нормальному распределению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_7_37.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формула плотности вероятности распределения Стьюдента выглядит следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ f(x)=\\frac{\\Gamma\\left(\\frac{v+1}{2}\\right)}{\\sqrt{v \\pi} \\Gamma\\left(\\frac{v}{2}\\right)}\\left(1+\\frac{x^2}{v}\\right)^{-\\frac{v+1}{2}} $\n",
    "<br>\n",
    "\n",
    "\n",
    "где:\n",
    "\n",
    "$ x $    — случайная переменная;\n",
    "<br> $v$    — число степеней свободы (degrees of freedom) распределения;\n",
    "<br>$ \\Gamma $    — функция Гамма, которая вычисляется для соответствующих аргументов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что для вычисления плотности вероятности распределения Стьюдента требуется использование функции Гамма, которая может быть определена отдельно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0fff3; padding: 15px; color: black; width: 80%;\">  <b>Гауссовское ядро (ядро Гаусса)</b> — это одна из распространённых ядерных функций, используемых в алгоритмах машинного обучения и обработки сигналов. Часто применяется в задачах сглаживания и фильтрации данных.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гауссовское ядро представляет собой функцию, которая зависит от расстояния между двумя точками и имеет форму колокола с пиком в нуле. Оно симметрично и уменьшается с расстоянием от пика.\n",
    "\n",
    "Гауссовское ядро используют для вычисления весовых коэффициентов в методе ядерного сглаживания (kernel smoothing). В этом методе каждая точка данных взвешивается с помощью функции гауссовского ядра в зависимости от её расстояния от интересующей нас точки.\n",
    "\n",
    "Ближние точки получают больший вес, тогда как дальние — меньший."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_7_38.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формула Гауссовского ядра выглядит следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ K\\left(x, x^{\\prime}\\right)=\\exp \\left(-\\frac{\\left\\|x-x^{\\prime}\\right\\|^2}{2 \\sigma^2}\\right) $\n",
    "<br>\n",
    "\n",
    "\n",
    "где:\n",
    "\n",
    "$ x $    и $ x^{\\prime}$ — две точки, между которыми мы вычисляем ядро;\n",
    "<br>$\\|x- x^{\\prime} \\|$    — расстояние между точками и ;\n",
    "<br>$\\sigma$    — параметр ширины ядра (стандартное отклонение).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В формуле используется евклидово расстояние между точками $x $ и $ x^{\\prime}$, и оно возведено в квадрат. Параметр определяет ширину ядра и влияет на размытость и распределение массы вокруг каждой точки.\n",
    "\n",
    "Гауссовское ядро широко применяется в алгоритмах машинного обучения, таких как метод опорных векторов (SVM) и метод гауссовских процессов (Gaussian Processes), а также в различных методах сглаживания и фильтрации данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0fff3; padding: 15px; color: black; width: 80%;\">  <b>Дивергенция Кульбака — Лейблера (Kullback–Leibler divergence, относительная энтропия)</b> — это мера различия между двумя вероятностными распределениями. Она широко применяется в области информационной теории и статистики для измерения расстояния между двумя распределениями.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дивергенция Кульбака — Лейблера между двумя вероятностными распределениями P и Q измеряет, насколько сильно распределение P отличается от распределения Q. Она не является метрикой расстояния, так как не обладает свойством симметричности, то есть KL-дивергенция между распределением P и распределением Q не равна KL-дивергенции между распределением Q и распределением P.\n",
    "\n",
    "Формула дивергенции Кульбака — Лейблера выглядит следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ D_{K L}(P \\| Q)=\\sum_i P(i) \\log \\left(\\frac{P(i)}{Q(i)}\\right) $\n",
    "<br>\n",
    "\n",
    "\n",
    "где:\n",
    "\n",
    "<br> $ D_{K L} $— дивергенция Кульбака — Лейблера;\n",
    "<br> $ P(i) $ и $Q(i) $— вероятности событий в распределениях P и Q соответственно;\n",
    "<br> $log$ — натуральный логарифм."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что дивергенцию Кульбака — Лейблера можно определить только в случае, когда все значения $ P(i)$ равны нулю, если $Q(i) $ равно нулю.\n",
    "\n",
    "Дивергенция Кульбака — Лейблера является положительной и неотрицательной и равна нулю только в случае, когда распределения P и Q совпадают."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуальная демонстрация алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Демонстрация алгоритма t-SNE представлена на рисунке ниже.\n",
    "\n",
    "Сначала необходимо загрузить в память исходную выборку с большим количеством признаков и случайным образом сгенерировать её отображение в признаковое пространство меньшей размерности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_7_39.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея алгоритма t-SNE заключается в том, чтобы сохранить близость объектов из исходного пространства в результирующем пространстве."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_7_40.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала вычисляют попарную сходственность (affinity) между всеми парами объектов в исходном пространстве. Обычно для оценки сходства между объектами используется гауссово ядро (гауссовское распределение). Сходство выражается числовыми значениями, которые показывают степень близости между объектами.\n",
    "\n",
    "Затем на основе попарных сходств вычисляют условные вероятности сходства между парами объектов. Эти вероятности вычисляются как отношение попарных сходств к сумме всех сходств, взятых с учётом попарных расстояний между объектами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_7_41.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Симметричность расстояний от точки до точки и перплексия — два важных фактора для правильного функционирования алгоритма t-SNE и получения высококачественных вложений. Симметричность расстояний для метрики означает, что расстояние от точки до точки и наоборот равны. Изначально в дивергенции Кульбака — Лейблера это не так.\n",
    "\n",
    "В алгоритме t-SNE усредняются расстояния от точки до точки и наоборот (то есть симметризация расстояний) для достижения более устойчивых и сбалансированных вложений в новом пространстве. Перплексия (perplexity) в теории информации — это мера сложности или неопределённости распределения вероятностей. Её используют в различных контекстах, включая машинное обучение и статистику.\n",
    "\n",
    "Математически перплексия определяется как экспонента энтропии распределения вероятностей. Для дискретного случая перплексия вычисляется следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\text { Perplexity }(P)=2^{-\\sum P(i) \\log _2 P(i)} $\n",
    "<br>\n",
    "где $P$ — распределение вероятностей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для непрерывного случая перплексию можно определить как:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\operatorname{Perplexity}(p(x))=\\exp \\left(-\\int p(x) \\log _2 p(x) d x\\right) $\n",
    "<br>\n",
    "где $ p(x) $ - плотность вероятности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перплексия в алгоритме t-SNE используется для контроля числа ближайших соседей, которые учитываются при вычислении условных вероятностей сходства. Высокое значение перплексии увеличивает влияние ближайших соседей, тогда как низкое её значение распространяет влияние на более широкий набор объектов.\n",
    "\n",
    "Выбор оптимального значения перплексии зависит от особенностей данных и требуемой структуры вложений. Подбор правильной перплексии позволяет достичь более точного отображения локальных сходств и сохранения структуры данных в новом пространстве."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_7_42.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Симметричность расстояний и перплексия взаимодействуют, чтобы учесть локальные отношения между объектами и сохранить структуру данных в новом пространстве.\n",
    "\n",
    "На каждой итерации алгоритма t-SNE вычисляется условная вероятность сходства объектов. Для каждой пары объектов $i$ и $j$ вычисляется условная вероятность\n",
    "$p_{ij}$ , которая отражает вероятность выбрать объект $j$ как соседа объекта $i$ при условии их исходного расположения в пространстве высокой размерности. Затем эти условные вероятности $p_{ij} $ сохраняются в матрице $P$ , где элемент $P_{ij}$ представляет собой условную вероятность сходства между объектами $i$ и $j$.\n",
    "\n",
    "Также на следующем шаге текущей итерации алгоритма t-SNE вычисляется условная вероятность в новом пространстве низкой размерности. Для каждой пары объектов в новом пространстве и $i$ и $i^{\\prime}$, вычисляется условная вероятность $q_{ij}$, которая отражает вероятность выбрать объект $j^{\\prime}$ как соседа объекта $j$.\n",
    "\n",
    "Эти условные вероятности $q_{ij}$ также сохраняются в матрице $Q$. Сохранение вероятностей сходства в матрицах $P$ и $Q$ является важным для дальнейшего вычисления расстояний и оптимизации вложений в пространстве низкой размерности.\n",
    "\n",
    "Далее происходит оптимизация расположения объектов в результирующем пространстве. Алгоритм стремится минимизировать расхождение между условными вероятностями сходства в исходном пространстве и результирующем пространстве с помощью дивергенции Кульбака — Лейблера. Оптимизация выполняется с помощью градиентного спуска.\n",
    "\n",
    "На каждой итерации оптимизации происходит обновление вложений (координат) объектов в результирующем пространстве. Обновление выполняется путём расчёта градиента и изменения координат объектов в направлении, которое минимизирует расхождение между вероятностями сходства объектов, сохранёнными в соответствующих матрицах.\n",
    "\n",
    "Алгоритм повторяется до достижения сходимости. Обычно определённое число итераций задаётся заранее, или алгоритм останавливается, когда изменение вложений становится незначительным.\n",
    "\n",
    "В результате работы алгоритма t-SNE получается новое представление данных в пространстве меньшей размерности, которое учитывает локальные сходства между объектами. Это позволяет визуализировать данные и обнаруживать структуры и паттерны, которые могут быть неочевидны в исходном пространстве высокой размерности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_7_43.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Процесс обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шаги алгоритма t-SNE:\n",
    "\n",
    "1.    Вычисление схожести. Сначала алгоритм вычисляет меру схожести между парами объектов в исходном пространстве. Обычно это делается с использованием гауссовского ядра или расстояния между точками, такого как евклидово расстояние.\n",
    "2.    Создание вероятностного распределения. Для каждой точки в исходном пространстве алгоритм вычисляет вероятностное распределение, отражающее схожесть между этой точкой и другими точками. Более похожим точкам присваивается более высокая вероятность.\n",
    "3.    Вычисление схожести в пространстве назначения. Затем алгоритм переходит в пространство назначения (обычно двух- или трёхмерное), где создаёт аналогичное вероятностное распределение. Он старается разместить точки таким образом, чтобы более похожие точки были ближе друг к другу.\n",
    "4.    Минимизация дивергенции Кульбака — Лейблера. Целью t-SNE является минимизация дивергенции Кульбака — Лейблера между вероятностными распределениями в исходном пространстве и пространстве назначения. Это достигается такой настройкой позиций точек в пространстве, чтобы минимизировать разницу между этими распределениями.\n",
    "5.    Градиентный спуск. Для минимизации дивергенции Кульбака — Лейблера алгоритм использует градиентный спуск. Он вычисляет градиент функционала ошибки и обновляет позиции точек, чтобы уменьшить ошибку. Обновление происходит итеративно, пока не будет достигнута сходимость.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы оценить качество работы t-SNE, можно использовать несколько метрик. Перечислим некоторые из них.\n",
    "\n",
    "Визуализация. Одним из наиболее популярных способов оценки качества t-SNE является визуальный анализ результатов. Просмотрите полученное низкоразмерное представление данных и оцените, насколько хорошо алгоритм сохраняет структуру и относительные расстояния между объектами. Убедитесь, что близкие объекты находятся близко друг к другу, а разные кластеры отделены друг от друга.\n",
    "\n",
    "Поддержка кластеризации. Если у вас есть информация о настоящих кластерах в данных, вы можете оценить, насколько хорошо t-SNE справляется с их выделением. Чтобы сравнить полученные кластеры с эталонными, используйте метрики, такие как Adjusted Rand Index (ARI), Normalized Mutual Information (NMI) или Silhouette Score.\n",
    "\n",
    "Сохранение расстояний. t-SNE должен сохранять относительные расстояния между объектами в исходном пространстве при их проецировании на низкоразмерное пространство. Вы можете вычислить попарные расстояния между объектами в исходном и низкоразмерном пространствах и сравнить их. Для оценки сходства между расстояниями можно использовать метрики, такие как Pearson correlation coefficient или Spearman rank correlation coefficient.\n",
    "\n",
    "Stochastic Neighbor Embedding (SNE) cost function. t-SNE оптимизирует функцию стоимости, основанную на SNE. Вы можете отслеживать значения функции стоимости на каждой итерации и проверять, сходится ли алгоритм. Если значения функции стоимости продолжают уменьшаться, это может быть индикатором успешной работы алгоритма.\n",
    "\n",
    "Важно отметить, что t-SNE является эвристическим алгоритмом и не существует универсальных метрик, которые идеально оценивают его качество. Оценка качества t-SNE должна основываться на комбинации различных метрик и визуальной интерпретации результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм t-SNE — мощный инструмент для визуализации исходных данных в низкоразмерном пространстве. Его можно использовать в различных областях, где требуется визуализация и анализ многомерных данных.\n",
    "\n",
    "Некоторые примеры применения алгоритма:\n",
    "\n",
    "-    Визуализация данных. Основное применение t-SNE заключается в визуализации сложных многомерных данных в двух или трёх измерениях. Это позволяет исследовать и понять структуру данных, выявить кластеры или группы объектов, обнаружить выбросы, аномалии, скрытые паттерны или зависимости. Примеры использования: визуализация геномных данных, изображений, текстовых данных и т. д.\n",
    "-    Кластеризация. t-SNE можно использовать для кластеризации данных на основе их визуализации в низкоразмерном пространстве. После проецирования данных на плоскость с помощью t-SNE можно применить алгоритмы кластеризации, такие как k-means или DBSCAN, для выделения кластеров и их анализа.\n",
    "-    Обнаружение аномалий. t-SNE может помочь в обнаружении аномалий или выбросов в данных. Объекты, которые отображаются далеко от основной структуры данных в низкоразмерном пространстве, могут считаться потенциальными аномалиями или интересными случаями, которые заслуживают дополнительного исследования.\n",
    "-    Предварительная обработка данных. t-SNE можно использовать как этап предварительной обработки данных для последующего применения других алгоритмов машинного обучения. Проецирование данных на низкоразмерное пространство с помощью t-SNE может улучшить эффективность и качество работы других алгоритмов, таких как классификация, регрессия или кластеризация.\n",
    "\n",
    "Важно отметить, что t-SNE является вычислительно сложным алгоритмом, особенно для больших наборов данных. Поэтому, чтобы применить его к большим данным, может потребоваться распараллеливание вычислений или использование других методов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Плюсы и минусы алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм t-SNE имеет несколько преимуществ, которые делают его популярным инструментом для визуализации и анализа данных.\n",
    "\n",
    "Плюсы:\n",
    "\n",
    "-    Сохранение локальной структуры. t-SNE стремится сохранить относительные расстояния между близкими объектами в исходном пространстве. Это означает, что объекты, которые находятся близко друг к другу в исходных данных, будут отображены близко друг к другу в низкоразмерном пространстве. Это позволяет сохранить локальную структуру данных и обнаружить кластеры или группы объектов.\n",
    "-    Устойчивость к выбросам. t-SNE обычно хорошо справляется с выбросами или аномалиями в данных. Из-за своего вероятностного подхода и использования тяжёлых хвостов распределения t-Student алгоритм t-SNE не так сильно подвержен влиянию выбросов и может помочь обнаружить их.\n",
    "-    Визуальная интерпретация. Одно из основных преимуществ t-SNE — его способность визуализировать высокоразмерные данные в двух или трёх измерениях. Это позволяет исследовать данные, выявлять паттерны и структуры, а также делать выводы и принимать решения на основе визуальной интерпретации результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наряду с преимуществами, алгоритм t-SNE также имеет некоторые ограничения и потенциальные недостатки.\n",
    "\n",
    "Минусы:\n",
    "\n",
    "-    Вычислительная сложность. Алгоритм t-SNE требует вычисления попарных расстояний между всеми парами точек в исходном пространстве. Это делает его вычислительно требовательным, особенно для больших наборов данных. Время выполнения может значительно возрастать с увеличением размерности исходных данных или числа объектов.\n",
    "-    Недетерминированность. t-SNE является стохастическим алгоритмом, что означает, что результаты могут немного различаться при каждом запуске. Это может затруднить воспроизводимость результатов и требует выполнения нескольких запусков для проверки стабильности и надёжности результатов.\n",
    "-    Потеря глобальной структуры. t-SNE сконцентрирован на сохранении локальной структуры данных и обнаружении кластеров. Однако из-за своей природы алгоритм может уменьшать различия между удалёнными объектами в низкоразмерном пространстве, что может привести к потере глобальной структуры данных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "В библиотеке scikit-learn алгоритм t-SNE (t-Distributed Stochastic Neighbor Embedding) реализован через <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\"> класс TSNE</a> из модуля sklearn.manifold.\n",
    "\n",
    "Основные параметры класса TSNE:\n",
    "\n",
    "    n_components — количество компонентов в низкоразмерном пространстве, в которое будет проецироваться исходное пространство данных. Обычно для визуализации это 2 или 3. Обязательный параметр.\n",
    "    perplexity — мера сложности глобальной структуры данных. Определяет баланс между сохранением локальной и глобальной структуры. Значения perplexity должны быть в диапазоне от 5 до 50, но часто используется значение около 30.\n",
    "    learning_rate — скорость обучения алгоритма. Определяет шаг изменения в низкоразмерном пространстве. Маленькое значение learning_rate может привести к более долгой сходимости, но более высокому качеству визуализации. Значения learning_rate обычно варьируются от 10 до 1000.\n",
    "    n_iter — количество итераций оптимизации алгоритма. Определяет количество шагов, которые алгоритм выполняет для достижения оптимального результата. Значение по умолчанию — 1000.\n",
    "\n",
    "В классе TSNE также имеются методы fit(X) — для обучения модели на данных X и transform(X) — для преобразования данных X в низкоразмерное пространство с использованием изученных компонент."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Давайте резюмируем.\n",
    "\n",
    "<b>t-SNE (t-Distributed Stochastic Neighbor Embedding)</b> — это алгоритм снижения размерности данных, который часто используется для отображения высокоразмерных данных на двух- или трёхмерное пространство. Он широко применяется для анализа и визуализации сложных наборов данных, таких как текст, аудио, графы и другие.\n",
    "\n",
    "Основная идея алгоритма t-SNE заключается в том, чтобы сохранить близость объектов из исходного пространства в результирующем пространстве. Алгоритм строит вероятностную модель, где объекты в исходном пространстве и в пространстве визуализации представлены вероятностными распределениями. Он пытается минимизировать расхождение между этими распределениями, чтобы сохранить связи и соседство между объектами.\n",
    "\n",
    "Для работы алгоритма t-SNE необходимо настроить параметры, такие как perplexity (параметр, определяющий баланс между сохранением локальной и глобальной структуры данных) и learning rate (параметр, регулирующий скорость обучения). Оптимальный выбор этих параметров может существенно влиять на качество визуализации.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
