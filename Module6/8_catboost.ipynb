{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель занятия — познакомиться с алгоритмом CatBoost, для которого характерна усовершенствованная обработка категориальных признаков. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуальная демонстрация алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0fff3; padding: 15px; color: black; width: 80%;\">  <b>CatBoost</b> — это алгоритм градиентного бустинга деревьев решений от компании «Яндекс». Он может обрабатывать большие объёмы данных и быстро обучается за счёт использования нескольких техник оптимизации, таких как категориальная обработка данных, симметричный случайный выбор (Symmetric Random Selection), использование градиентов второго порядка (Hessian).</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <b>Одно из основных преимуществ CatBoost</b> — его способность автоматически обрабатывать категориальные признаки, не требуя их предобработки. Это может значительно ускорить процесс обучения модели.\n",
    "\n",
    "В отличие от LightGBM, в CatBoost используется стратегия обучения по слоям (level-wise): на каждом уровне дерева одновременно выбираются все узлы для разделения, что позволяет более полно использовать информацию о данных. Это может способствовать повышению точности модели, но также может увеличить время обучения.\n",
    "\n",
    "В CatBoost используется структура дерева <b>Oblivious Decision Tree</b> — алгоритм построения дерева решений, который относится к классу неведущих (oblivious) алгоритмов.\n",
    "\n",
    "В отличие от обычных деревьев решений, которые могут использовать различные признаки на каждом уровне дерева, неведущие деревья используют только один и тот же признак на каждом уровне дерева. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_6_9.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " CatBoost поддерживает распределённое обучение на нескольких компьютерах, многоклассовую классификацию и регрессию.\n",
    "\n",
    "<b>Общие шаги алгоритма CatBoost</b>:\n",
    "\n",
    "1. Предобработка данных и подготовка набора признаков.\n",
    "2. Обучение базовых моделей на первоначальном наборе данных.\n",
    "3. Создание и обучение ансамбля базовых моделей с использованием градиентного бустинга.\n",
    "4. Вычисление ошибки на каждой итерации градиентного бустинга и пересчёт весов моделей с учётом ошибки.\n",
    "5. Применение ансамбля моделей на новых данных для решения задачи классификации или регрессии.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; padding: 15px; color: black; width: 80%;\">CatBoost отличается от других алгоритмов градиентного бустинга тем, что он автоматически обрабатывает категориальные признаки и не требует их предварительного преобразования. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных для алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Подготовка данных для алгоритма CatBoost может включать в себя <b>обработку пропущенных значений</b>: если в данных есть пропуски, заполните их средними, медианами или другими подходящими значениями. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Процесс обучения\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Процесс обучения CatBoost включает в себя следующие шаги:\n",
    "\n",
    "1. Подготовка данных и определение набора признаков.\n",
    "2. Определение гиперпараметров модели, таких как количество деревьев, глубина деревьев, скорость обучения и т. д.\n",
    "3. Обучение базовых моделей на первоначальном наборе данных.\n",
    "4. Создание ансамбля базовых моделей с использованием градиентного бустинга.\n",
    "5. Оценка качества модели на проверочном наборе данных, чтобы определить оптимальное число итераций и избежать переобучения.\n",
    "6. Применение обученной модели для решения задачи классификации или регрессии.\n",
    "\n",
    "CatBoost также поддерживает автоматическое кодирование категориальных признаков, встроенную кросс-валидацию и техники борьбы с переобучением — регуляризацию и сокращение градиента. Кроме того, CatBoost позволяет использовать несколько процессоров и графические процессоры для ускорения обучения модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <b>Особенности обучения CatBoost:</b>\n",
    "\n",
    "- <b>Обработка отсутствующих значений</b>. CatBoost обрабатывает отсутствующие значения с помощью специального токена, чтобы модель могла корректно обработать данные.\n",
    "- <b>Регуляризация.</b> CatBoost применяет регуляризацию, чтобы контролировать сложность модели и избегать переобучения, а также использует методы сокращения данных и ограничения глубины деревьев.\n",
    "- <b>Подбор гиперпараметров</b>. CatBoost позволяет настраивать множество гиперпараметров, таких как глубина дерева, скорость обучения, количество деревьев и др. Для нахождения оптимальных настроек модели можно использовать встроенные функции подбора гиперпараметров.\n",
    "- <b>Параллельное обучение</b>. CatBoost может обучаться параллельно на многих ядрах процессора, что позволяет сократить время обучения моделей и ускорить процесс выбора оптимальных гиперпараметров.\n",
    "- <b>Обработка категориальных признаков</b>. CatBoost имеет уникальный алгоритм для работы с категориальными признаками, который позволяет автоматически преобразовывать категориальные признаки в числовые значения, не требуя предобработки данных.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <b>Важные параметры при обучении CatBoost:</b>\n",
    "\n",
    "- learning_rate — скорость обучения, которая определяет, насколько сильно корректируются веса при обновлении модели на каждой итерации. Этот параметр влияет на скорость сходимости модели и на её способность к обобщению.\n",
    "- depth — максимальная глубина дерева, которая определяет количество уровней дерева решений. Этот параметр влияет на способность модели к обобщению и на скорость обучения.\n",
    "- l2_leaf_reg — коэффициент L2-регуляризации весов у листьев деревьев. Этот параметр влияет на скорость обучения и на способность модели к обобщению.\n",
    "- min_data_in_leaf — минимальное количество образцов в листе дерева. Этот параметр влияет на устойчивость модели к шуму и на её способность к обобщению.\n",
    "- max_bin — максимальное количество корзин для гистограммного метода построения деревьев. Этот параметр влияет на скорость обучения и на качество модели.\n",
    "- subsample — доля выборки, используемая для обучения каждого дерева. Этот параметр влияет на способность модели к обобщению и на устойчивость к переобучению.\n",
    "- random_strength — сила случайности, используемая при выборе случайных признаков для обучения каждого дерева. Этот параметр влияет на устойчивость к переобучению и на качество модели.\n",
    "- bagging_temperature — температура распределения Больцмана, которая используется при выборе объектов для обучения каждого дерева. Этот параметр влияет на способность модели к обобщению и на устойчивость к переобучению.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки качества алгоритма CatBoost часто используют следующие метрики:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Accuracy:</b> $\\frac{TP+TN}{TP+TN+FP+FN}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Precision:</b>$\\frac{TP}{TP+FP}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Recall:</b>$\\frac{TP}{TP+FN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>F1: </b> $2* \\frac{precision*recall}{precision+recall}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MSE\n",
    "- MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Интерпретация признаков с помощью алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " CatBoost предлагает различные методы интерпретации признаков, которые помогают оценить важность признаков и их влияние на предсказания модели.\n",
    "\n",
    "- Важность признаков. CatBoost предоставляет встроенную функцию, которая рассчитывает важность признаков на основе их использования в деревьях решений. Важность можно использовать для определения наиболее значимых признаков, влияющих на целевую переменную.\n",
    "- SHAP-значения. CatBoost поддерживает расчёт SHAP-значений для интерпретации модели. SHAP-значения позволяют определить влияние каждого признака на предсказание модели и объяснить, почему модель даёт определённые предсказания. Это может быть полезным для понимания важности и влияния признаков.\n",
    "- Визуализация деревьев. CatBoost позволяет визуализировать деревья решений, построенные в ходе обучения модели. Визуализация деревьев позволяет лучше понять, какие признаки используются в модели и как они влияют на предсказание.\n",
    "- Предсказания на новых данных. При предсказаниях на новых данных в CatBoost можно оценить важность признаков. Если признаки не важны для предсказания на новых данных, их можно удалить из модели.\n",
    "\n",
    "Эти методы интерпретации признаков помогают разобраться в модели и понять, какие признаки наиболее важны для её предсказаний. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " CatBoost широко используется в различных областях для решения следующих задач:\n",
    "\n",
    " -   Реклама и маркетинг — прогнозирование кликов и конверсий, оптимизация рекламных кампаний, персонализация рекомендаций.\n",
    " -   Финансы — оценка кредитного скоринга, обнаружение мошеннических операций, прогнозирование рыночных трендов.\n",
    " -   Здравоохранение — диагностика заболеваний, прогнозирование рисков, анализ медицинских изображений.\n",
    " -   Интернет-магазины — рекомендательные системы, прогнозирование спроса, управление ассортиментом.\n",
    " -   Телекоммуникации — прогнозирование оттока клиентов, оптимизация сетей связи.\n",
    " -   Транспорт и логистика — оптимизация маршрутов, прогнозирование задержек, управление логистическими процессами.\n",
    " -   Энергетика — прогнозирование потребления энергии, оптимизация энергетических сетей.\n",
    "\n",
    "CatBoost показывает хорошую производительность в задачах с большим числом категориальных признаков и может эффективно работать с разрежёнными данными. Его также можно применять в задачах обработки естественного языка, компьютерного зрения и в других областях, где требуется классификация и регрессия. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Плюсы и минусы алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \t😃 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Обработка категориальных признаков. CatBoost автоматически обрабатывает категориальные признаки без необходимости их предобработки. Это упрощает процесс подготовки данных и позволяет моделировать задачи с большим количеством категориальных признаков.\n",
    "- Устойчивость к переобучению. CatBoost включает в себя встроенные методы регуляризации, которые помогают предотвратить переобучение модели. Это делает его более устойчивым к шуму и выбросам в данных.\n",
    "- Высокая точность и обобщающая способность. CatBoost показывает хорошие результаты на различных задачах и способен обобщать на новые данные. Он обладает высокой предсказательной точностью при правильной настройке гиперпараметров.\n",
    "- Эффективное использование категориальных признаков. CatBoost использует специальный алгоритм для эффективной обработки категориальных признаков, что позволяет получать более точные предсказания.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "😥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Длительное время обучения. В некоторых случаях обучение CatBoost может требовать больше времени по сравнению с другими алгоритмами градиентного бустинга, особенно при большом количестве категориальных признаков.\n",
    "- Требуется настройка гиперпараметров. У CatBoost есть множество гиперпараметров, которые необходимо настроить для достижения наилучшей производительности модели. Это может потребовать затрат времени и вычислительных ресурсов.\n",
    "- Большое потребление памяти. Для обработки больших объёмов данных со множеством признаков CatBoost требует соответствующего объёма памяти, особенно при использовании GPU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; padding: 15px; color: black; width: 80%;\">В целом, CatBoost — это мощный алгоритм градиентного бустинга с хорошей поддержкой категориальных признаков. Однако для него необходимо настраивать гиперпараметры. Также он может потребовать больше вычислительных ресурсов. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost реализован в библиотеке <a href=\"https://catboost.ai/en/docs/\">CatBoost</a>. В ней для задач классификации существует класс CatBoostClassifier, а для задач регрессии — класс CatBoostRegressor.\n",
    "\n",
    "Основные параметры классов CatBoostClassifier и CatBoostRegressor:\n",
    "\n",
    "- loss_function — целевая функция, которую оптимизирует CatBoost.\n",
    "    - Поддерживаемые целевые функции для задач классификации: Logloss, CrossEntropy, MultiClass, MultiClassOneVsAll, AUC, F1, Accuracy, PRAUC, Recall, Precision, BalancedAccuracy.\n",
    "    - Поддерживаемые целевые функции для задач регрессии: MAE, MAPE, Poisson, Quantile, RMSE, SquaredLoss, Huber, LogLinQuantile.\n",
    "- n_estimators — количество деревьев в градиентном бустинге. По умолчанию n_estimators=1000.\n",
    "- learning_rate — шаг обучения, который контролирует вклад каждого дерева. По умолчанию learning_rate=0.03.\n",
    "- max_depth — максимальная глубина каждого дерева. По умолчанию max_depth=6.\n",
    "- num_leaves — максимальное количество листьев в каждом дереве. По умолчанию num_leaves=31.\n",
    "- min_data_in_leaf — минимальное количество элементов, которые должны быть в листьях дерева. По умолчанию min_data_in_leaf=1.\n",
    "- colsample_bylevel — количество признаков, которые должны быть рассмотрены при каждом разделении на каждом уровне дерева. По умолчанию colsample_bylevel=1.0.\n",
    "- subsample — доля элементов, которые должны быть использованы при построении каждого дерева. По умолчанию subsample=1.0.\n",
    "- random_seed — начальное значение для генератора случайных чисел. По умолчанию random_seed=None.\n",
    "\n",
    "\n",
    "Классы CatBoostClassifier и CatBoostRegressor имеют методы:\n",
    "\n",
    "- fit(X, y) — для обучения модели на данных X и y;\n",
    "- predict(X) — для предсказания целевых значений для новых данных X;\n",
    "- score(X, y) и get_params() — для получения оценки точности модели и параметров модели соответственно.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid white; padding: 5px; margin-right: auto;  width: 80%;\">\n",
    "\n",
    "Давайте резюмируем:\n",
    "\n",
    "- CatBoost — это ещё один быстрый и эффективный алгоритм градиентного бустинга деревьев решений, который также использует уникальные техники построения деревьев и обработки данных. Он имеет ряд преимуществ перед другими алгоритмами, включая автоматическую обработку категориальных признаков, быструю скорость обучения и предсказания, а также поддержку распределённого обучения.\n",
    "- CatBoost также обеспечивает автоматическую настройку гиперпараметров, что может улучшить качество модели.\n",
    "- CatBoost можно использовать для задач классификации, регрессии и ранжирования.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; padding: 15px; color: black; width: 80%;\">В этом модуле мы познакомились с бустингом и с моделями, которые работают на его основе: AdaBoost, XGBoost, LightGBM и CatBoost.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вы знаете:\n",
    "\n",
    "-    как подготавливать данные для этих алгоритмов и обучать их;\n",
    "-    оценивать качество полученных моделей;\n",
    "-    интерпретировать признаки;\n",
    "-    реализовывать эти алгоритмы в Python.\n",
    "\n",
    "Кроме того, мы изучили преимущества и недостатки каждого из алгоритмов, сферы их применения и задачи, которые они могут решать.\n",
    "\n",
    "Кратко обозначим основные моменты.\n",
    "\n",
    "<b>Бустинг </b>— это метод машинного обучения, который позволяет улучшить качество прогнозов, создаваемых слабыми моделями машинного обучения. При использовании этого метода каждая последующая базовая модель фокусируется на примерах, которые были неправильно классифицированы предыдущими моделями, что позволяет создать сильную модель, которая даёт более точные прогнозы.\n",
    "\n",
    "Существует два подхода к реализации бустинга: AdaBoost и градиентный бустинг. AdaBoost создаёт последовательность слабых взвешенных моделей машинного обучения и комбинирует их в единую сильную модель. Градиентный бустинг использует градиент, настраиваемый на остатки (разность между предсказаниями текущей модели и правильными ответами предыдущих моделей), чтобы определить, какие примеры данных неправильно классифицировали предыдущие модели, и насколько сильно эти примеры влияют на функцию потерь.\n",
    "\n",
    "<b>XGBoost, LightGBM и CatBoost</b> — эффективные и мощные алгоритмы градиентного бустинга для задач классификации и регрессии. Они используют градиентный бустинг деревьев решений для улучшения качества модели путём последовательного добавления новых деревьев и корректировки ошибок предыдущих.\n",
    "\n",
    "Основные преимущества:\n",
    "\n",
    "-    XGBoost — высокая скорость обучения и предсказания, возможность работы с большими объёмами данных, устойчивость к переобучению и возможность интерпретации результатов;\n",
    "-    LightGBM — меньшее время обучения, более высокая скорость предсказания и меньшее потребление памяти по сравнению с другими алгоритмами градиентного бустинга;\n",
    "-    CatBoost — автоматическая обработка категориальных признаков, быстрая скорость обучения и предсказания, поддержка распределённого обучения.\n",
    "\n",
    "Все три алгоритма предоставляют множество параметров, которые можно настраивать и тем самым влиять на качество модели. Алгоритмы можно использовать для задач классификации, регрессии и ранжирования. Однако выбор алгоритма зависит от конкретной задачи и требований к модели."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
