{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель занятия — познакомиться с алгоритмом LightGBM, который использует стратегию построения деревьев по листьям, что приводит к более быстрому построению дерева."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуальная демонстрация алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e0fff3; padding: 15px; color: black; width: 80%;\">  <b>LightGBM</b> — это алгоритм градиентного бустинга деревьев решений, который разработан Microsoft и считается одним из наиболее быстрых и эффективных.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; padding: 15px; color: black; width: 80%;\"><b>Основные преимущества LightGBM</b> — его способность работать с большими объёмами данных и быстрая скорость обучения модели. Это достигается за счёт использования нескольких техник оптимизации: основанной на гистограммах обработки данных, локальной оценки градиента (GOSS) и сжатия данных (компактное представление данных).</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от других алгоритмов градиентного бустинга, в которых используется стратегия обучения по слоям (level-wise), в LightGBM используется стратегия обучения по листьям (leaf-wise):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/module_6_8.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При построении дерева алгоритм на каждом шаге выбирает тот лист, который максимально уменьшает функцию потерь, и строит дочерние узлы от этого листа. Таким образом, в LightGBM каждое дерево может иметь разную глубину, что позволяет модели улавливать более сложные зависимости в данных. Также это позволяет LightGBM строить деревья с меньшим количеством узлов, что уменьшает сложность модели и ускоряет время обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f5f5f5; padding: 15px; color: black; width: 80%;\">Однако стратегия leaf-wise может привести к переобучению, особенно если выборка содержит выбросы или шумы. Поэтому в LightGBM реализован ряд механизмов для предотвращения переобучения — регуляризация и early stopping.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, LightGBM поддерживает распределённое обучение на нескольких компьютерах, многоклассовую классификацию и регрессию.\n",
    "\n",
    "<b>Общие шаги алгоритма LightGBM:</b>\n",
    "\n",
    "-    Построение гистограмм для свойств.\n",
    "-    Обучение деревьев решений с использованием градиентного бустинга.\n",
    "-    Пересчёт градиента и гессиана на каждой итерации для обновления весов деревьев.\n",
    "-    Вычисление прогноза модели на новых данных.\n",
    "\n",
    "LightGBM — это быстрый и эффективный алгоритм градиентного бустинга, который можно использовать для решения задач классификации и регрессии на больших объёмах данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных для алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка данных для алгоритма LightGBM может включать в себя следующие шаги:\n",
    "\n",
    "-    Обработка выбросов. Для достижения лучшей производительности рекомендуется предварительно обработать выбросы.\n",
    "-    Обработка пропущенных значений. Если есть пропущенные значения, заполните их средними значениями, медианами или другими подходящими значениями.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Процесс обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Процесс обучения LightGBM включает в себя следующие шаги:\n",
    "\n",
    "1. Подготовка данных.\n",
    "2. Подготовка параметров модели. У LightGBM есть множество гиперпараметров, которые можно настроить для достижения наилучшей производительности модели.\n",
    "3. Создание деревьев. LightGBM использует алгоритм, основанный на градиентном бустинге деревьев решений. На каждой итерации модель добавляет новое дерево, которое пытается уменьшить остаточную ошибку предыдущей модели.\n",
    "4. Прогнозирование. После построения модели можно использовать её для прогнозирования новых значений. LightGBM позволяет делать прогнозы как для задач классификации, так и для задач регрессии.\n",
    "5. Тюнинг гиперпараметров. Как и в случае с другими моделями машинного обучения, можно провести тюнинг гиперпараметров для достижения наилучшей производительности модели. У LightGBM есть множество гиперпараметров, которые можно настроить для улучшения качества модели.\n",
    "6. Повторение. Шаги 2–4 можно повторить несколько раз для достижения наилучшей производительности модели.\n",
    "\n",
    "В результате обучения LightGBM получается ансамбль деревьев решений, которые были построены поэтапно с помощью градиентного бустинга. LightGBM работает быстро и обладает хорошей производительностью на больших наборах данных. Кроме того, LightGBM поддерживает параллельное выполнение и распределённое обучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Особенности обучения LightGBM:</b>\n",
    "\n",
    "1. Обработка отсутствующих значений. LightGBM поддерживает обработку отсутствующих значений в данных, но лучше делать их предобработку.\n",
    "2. Регуляризация. LightGBM применяет регуляризацию для контроля сложности модели и во избежание переобучения, а также использует методы сокращения данных и ограничения глубины деревьев.\n",
    "3. Подбор гиперпараметров. LightGBM позволяет настраивать множество гиперпараметров, таких как глубина дерева, скорость обучения, количество деревьев и др. Это позволяет найти оптимальные настройки модели для конкретной задачи.\n",
    "4. Автоматический выбор признаков. LightGBM может автоматически выбирать наиболее важные признаки для моделирования. Это происходит путём оценки важности признаков на основе их вклада в улучшение целевой функции, но также можно использовать внешние алгоритмы выбора признаков.\n",
    "5. Параллельное обучение. LightGBM может обучаться параллельно на многих ядрах процессора, что позволяет сократить время обучения моделей и ускорить процесс выбора оптимальных гиперпараметров.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важные параметры при обучении LightGBM:\n",
    "\n",
    " -   learning_rate — скорость обучения, которая определяет, насколько сильно корректируются веса при обновлении модели на каждой итерации. Выбор этого параметра влияет на скорость сходимости модели и на её способность к обобщению.\n",
    "-    max_depth — максимальная глубина дерева, которая определяет количество уровней дерева решений. Выбор этого параметра влияет на способность модели к обобщению и на скорость обучения.\n",
    "-    min_child_samples — минимальное количество образцов, необходимых для создания нового узла. Выбор этого параметра влияет на устойчивость модели к шуму и на её способность к обобщению.\n",
    "-    min_child_weight — минимальная величина веса дочернего узла, чтобы продолжать делить узел. Выбор этого параметра влияет на устойчивость модели к шуму и на её способность к обобщению.\n",
    "-    subsample — доля выборки, используемая для обучения каждого дерева. Выбор этого параметра влияет на способность модели к обобщению и на устойчивость к переобучению.\n",
    "-    colsample_bytree — доля признаков, используемых для обучения каждого дерева. Выбор этого параметра влияет на способность модели к обобщению и на устойчивость к переобучению.\n",
    "-    reg_alpha — коэффициент L1-регуляризации весов деревьев. Выбор этого параметра влияет на скорость обучения и на способность модели к обобщению.\n",
    "-    reg_lambda — коэффициент L2-регуляризации весов деревьев. Выбор этого параметра влияет на скорость обучения и на способность модели к обобщению.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки качества алгоритма LightGBM часто используют следующие метрики:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Accuracy:</b> $\\frac{TP+TN}{TP+TN+FP+FN}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Precision:</b>$\\frac{TP}{TP+FP}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Recall:</b>$\\frac{TP}{TP+FN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>F1: </b> $2* \\frac{precision*recall}{precision+recall}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MSE\n",
    "- MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Интерпретация признаков с помощью алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы интерпретировать признаки в LightGBM, можно использовать следующие методы:\n",
    "\n",
    "-    Важность признаков. В LightGBM есть встроенная функция, которая рассчитывает важность признаков на основе их использования в деревьях решений. Важность можно использовать для определения наиболее значимых признаков, влияющих на целевую переменную.\n",
    "-    SHAP-значения. SHAP (SHapley Additive exPlanations) — это метод интерпретации модели, который позволяет определить влияние каждого признака на её предсказание. LightGBM поддерживает SHAP-значения, которые можно рассчитать для каждого образца в данных. SHAP-значения можно использовать для объяснения причин, по которым модель даёт определённые предсказания.\n",
    "-    Визуализация деревьев решений. LightGBM позволяет визуализировать деревья решений, созданные в ходе обучения модели. Благодаря визуализации деревьев легче понимать, какие признаки используются в модели и как они влияют на предсказание.\n",
    "-    Предсказания на новых данных. LightGBM позволяет делать предсказания на новых данных. Если такие предсказания достаточно точны, можно использовать их для определения важности признаков. Если признаки не важны для предсказания на новых данных, их можно удалить из модели.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные области применения LightGBM включают в себя:\n",
    "\n",
    "    Финансы — прогнозирование кредитных рисков, анализ финансовых рынков.\n",
    "    Реклама — прогнозирование эффективности рекламы, оптимизация бюджета рекламных кампаний.\n",
    "    Интернет-магазины — рекомендательные системы, прогнозирование продаж, сегментация аудитории.\n",
    "    Обработка естественного языка — классификация текстов, анализ тональности, машинный перевод.\n",
    "    Изображения и видео — распознавание объектов, классификация изображений, анализ видео.\n",
    "    Промышленность — мониторинг и управление качеством продукции, прогнозирование отказов оборудования.\n",
    "    Транспорт и логистика — прогнозирование спроса на перевозки, оптимизация маршрутов, анализ логистических данных.\n",
    "\n",
    "В целом, LightGBM может быть полезным в любой области, где требуется классификация или регрессия на основе большого количества признаков и где есть достаточно данных для обучения модели. Он также может пригодиться для решения задач, связанных с обработкой естественного языка и изображений, и задач прогнозирования в различных отраслях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Плюсы и минусы алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \t😃 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Высокая скорость обучения. LightGBM использует алгоритм градиентного бустинга, который позволяет быстро обучать модель на больших объёмах данных.\n",
    "- Высокая точность предсказаний. LightGBM способен достичь высокой точности предсказаний, особенно при использовании большого количества деревьев.\n",
    "- Эффективное использование памяти. LightGBM использует специальную структуру данных, которая позволяет эффективно использовать память и ускоряет обучение модели.\n",
    "- Гибкость в настройке. В LightGBM можно настраивать множество гиперпараметров, что позволяет добиться наилучшей производительности модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "😥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Чувствительность к шуму и выбросам. LightGBM может быть чувствителен к шуму и выбросам в данных, что может приводить к переобучению.\n",
    "- Неэффективность при большом количестве категориальных признаков со множеством уникальных значений. В этом случае может возникнуть проблема переобучения.\n",
    "- Требуется подбор гиперпараметров. Для достижения наилучшей производительности модели необходимо подобрать оптимальные гиперпараметры.\n",
    "- Неинтерпретируемость. LightGBM не обеспечивает полного понимания, как именно происходит принятие решения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM реализован в библиотеке <a href=\"https://lightgbm.readthedocs.io/en/latest/\">lightgbm</a>. В ней для задач классификации существует класс LGBMClassifier, а для задач регрессии — класс LGBMRegressor.\n",
    "\n",
    "Основные параметры классов LGBMClassifier и LGBMRegressor:\n",
    "\n",
    "-   objective — целевая функция, которую оптимизирует LightGBM.\n",
    "    -    Поддерживаемые целевые функции для задач классификации: binary, multiclass, multiclassova, cross_entropy, cross_entropy_lambda, xentropy, xentlambda, lambdarank, rank_xendcg, rank_xendcg_5, rank_xendcg_10, rank_ndcg, rank_ndcg_5, rank_ndcg_10, regression, regression_l1, huber, fair, poisson, gamma, tweedie, quantile, mape, gamma_regression, tweedie_regression.\n",
    "    -  Поддерживаемые целевые функции для задач регрессии: regression, regression_l1, huber, fair, poisson, quantile, mape, gamma, tweedie, gamma_regression, tweedie_regression.\n",
    "- n_estimators — количество деревьев в градиентном бустинге. По умолчанию n_estimators=100.\n",
    "- learning_rate — шаг обучения, который контролирует вклад каждого дерева. По умолчанию learning_rate=0.1.\n",
    "- max_depth — максимальная глубина каждого дерева. По умолчанию max_depth=-1. Это означает, что деревья разрастаются до тех пор, пока не будет достигнуто минимальное количество элементов для разделения.\n",
    "- num_leaves — максимальное количество листьев в каждом дереве. По умолчанию num_leaves=31.\n",
    "- min_data_in_leaf — минимальное количество элементов, которые должны быть в листьях дерева. По умолчанию min_data_in_leaf=20.\n",
    "- min_child_samples — минимальное количество элементов, необходимое для того, чтобы узел можно было разделить на два подузла. По умолчанию min_child_samples=20.\n",
    "- feature_fraction — количество признаков, которые должны быть рассмотрены при каждом разделении. По умолчанию feature_fraction=1.0.\n",
    "- bagging_fraction — доля элементов, которые должны быть использованы при построении каждого дерева. По умолчанию bagging_fraction=1.0.\n",
    "- bagging_freq — частота использования случайных элементов для построения каждого дерева. По умолчанию bagging_freq=0.\n",
    "\n",
    "Классы LGBMClassifier/LGBMRegressor имеют методы:\n",
    "\n",
    "- fit(X, y) — для обучения модели на данных X и y;\n",
    "- predict(X) — для предсказания целевых значений для новых данных X;\n",
    "- score(X, y) и get_params() — для получения оценки точности модели и параметров модели соответственно.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
